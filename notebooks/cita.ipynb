{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>essay</th>\n",
       "      <th>sequence_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>4355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>3375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>4466</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>5217</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>5310</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>A_4314</td>\n",
       "      <td>4613</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>A_4314</td>\n",
       "      <td>4314</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>A_4131</td>\n",
       "      <td>4216</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>A_4131</td>\n",
       "      <td>4131</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>A_4131</td>\n",
       "      <td>4850</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>839 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     author essay  sequence_abs\n",
       "0    A_3375  4355             0\n",
       "1    A_3375  3375             1\n",
       "2    A_3375  4466             2\n",
       "3    A_3375  5217             3\n",
       "4    A_3375  5310             4\n",
       "..      ...   ...           ...\n",
       "834  A_4314  4613             7\n",
       "835  A_4314  4314             8\n",
       "836  A_4131  4216             7\n",
       "837  A_4131  4131             9\n",
       "838  A_4131  4850             9\n",
       "\n",
       "[839 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from langlearn.dataprep.utils import read_cita_tsv\n",
    "\n",
    "data_prefix = './langlearn/data'\n",
    "training_cita_tsv = data_prefix+'/raw/LangLearn_Training_Data/CItA/Training_CItA.tsv'\n",
    "\n",
    "df,tsv_train = read_cita_tsv(training_cita_tsv)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [essay, predicted, probability_B1, probability_B2, probability_C1, probability_C2, scalarFeatures_Depth of the Parse Trees_0, scalarFeatures_Lexical Diversity_0, scalarFeatures_Maximal Non-Verbal Phrase - Mean_0, scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0, scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0, scalarFeatures_Non-Verbal Chains Length - Mean_0, scalarFeatures_Non-Verbal Chains Length - Std.Dev._0, scalarFeatures_Referential Cohesion - Mean_0, scalarFeatures_Referential Cohesion - Std.Dev._0, scalarFeatures_Sentence Length (in Tokens) - Mean_0, scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0, scalarFeatures_Subordinate Ratio - Mean_0, scalarFeatures_Subordinate Ratio - Std.Dev._0, scalarFeatures_Text Length (in Lemmas)_0, scalarFeatures_Text Length (in Sentences)_0, scalarFeatures_Token Length - Mean_0, scalarFeatures_Token Length - Std.Dev._0, scalarFeatures_Verbal Roots_0, simpleScalarFeatures_Lunghezza del testo_0, simpleScalarFeatures_Lunghezza media delle frasi_0, simpleScalarFeatures_Varietà lessicale_0, distrFeatures_Arity of Verbal Predicates_ 0 _0, distrFeatures_Arity of Verbal Predicates_ 1 _0, distrFeatures_Arity of Verbal Predicates_ 2 _0, distrFeatures_Arity of Verbal Predicates_ 3 _0, distrFeatures_Arity of Verbal Predicates_ 4 _0, distrFeatures_Arity of Verbal Predicates_Std.Dev._0, distrFeatures_Arity of Verbal Predicates_≥ 5_0, distrFeatures_Basic Vucabulary Rate_Fundamentals_0, distrFeatures_Basic Vucabulary Rate_High Availability_0, distrFeatures_Basic Vucabulary Rate_High Usage_0, distrFeatures_Deep Causal Cohesion_Entropy_0, distrFeatures_Deep Causal Cohesion_additive_0, distrFeatures_Deep Causal Cohesion_adversative_0, distrFeatures_Deep Causal Cohesion_alternative_0, distrFeatures_Deep Causal Cohesion_causal_0, distrFeatures_Deep Causal Cohesion_marking results_0, distrFeatures_Deep Causal Cohesion_reformulation_0, distrFeatures_Deep Causal Cohesion_temporal_0, distrFeatures_Deep Causal Cohesion_transitions_0, distrFeatures_Dependency Links Length_Max_0, distrFeatures_Dependency Links Length_Mean_0, distrFeatures_Dependency Links Length_Std.Dev._0, distrFeatures_Dependency Tags Distribution_Entropy_0, distrFeatures_Dependency Tags Distribution_acl_0, distrFeatures_Dependency Tags Distribution_advcl_0, distrFeatures_Dependency Tags Distribution_advmod_0, distrFeatures_Dependency Tags Distribution_amod_0, distrFeatures_Dependency Tags Distribution_appos_0, distrFeatures_Dependency Tags Distribution_aux_0, distrFeatures_Dependency Tags Distribution_case_0, distrFeatures_Dependency Tags Distribution_cc_0, distrFeatures_Dependency Tags Distribution_ccomp_0, distrFeatures_Dependency Tags Distribution_compound_0, distrFeatures_Dependency Tags Distribution_conj_0, distrFeatures_Dependency Tags Distribution_cop_0, distrFeatures_Dependency Tags Distribution_csubj_0, distrFeatures_Dependency Tags Distribution_det_0, distrFeatures_Dependency Tags Distribution_discourse_0, distrFeatures_Dependency Tags Distribution_dislocated_0, distrFeatures_Dependency Tags Distribution_expl_0, distrFeatures_Dependency Tags Distribution_fixed_0, distrFeatures_Dependency Tags Distribution_flat_0, distrFeatures_Dependency Tags Distribution_iobj_0, distrFeatures_Dependency Tags Distribution_mark_0, distrFeatures_Dependency Tags Distribution_nmod_0, distrFeatures_Dependency Tags Distribution_nsubj_0, distrFeatures_Dependency Tags Distribution_nummod_0, distrFeatures_Dependency Tags Distribution_obj_0, distrFeatures_Dependency Tags Distribution_obl_0, distrFeatures_Dependency Tags Distribution_parataxis_0, distrFeatures_Dependency Tags Distribution_punct_0, distrFeatures_Dependency Tags Distribution_root_0, distrFeatures_Dependency Tags Distribution_vocative_0, distrFeatures_Dependency Tags Distribution_xcomp_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0, distrFeatures_Lexical Variation Feature_Adj A_0, distrFeatures_Lexical Variation Feature_Adj B_0, distrFeatures_Lexical Variation Feature_Adv A_0, distrFeatures_Lexical Variation Feature_Adv B_0, distrFeatures_Lexical Variation Feature_Noun A_0, distrFeatures_Lexical Variation Feature_Noun B_0, distrFeatures_Lexical Variation Feature_Verb A_0, distrFeatures_Lexical Variation Feature_Verb B_0, distrFeatures_MCI (Morphological Complexity Index)_Nouns_0, distrFeatures_MCI (Morphological Complexity Index)_Verbs_0, distrFeatures_Nouns Abstractness Distribution_Abstract_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 157 columns]\n",
      "Empty DataFrame\n",
      "Columns: [essay, predicted, probability_B1, probability_B2, probability_C1, probability_C2, scalarFeatures_Depth of the Parse Trees_0, scalarFeatures_Lexical Diversity_0, scalarFeatures_Maximal Non-Verbal Phrase - Mean_0, scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0, scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0, scalarFeatures_Non-Verbal Chains Length - Mean_0, scalarFeatures_Non-Verbal Chains Length - Std.Dev._0, scalarFeatures_Referential Cohesion - Mean_0, scalarFeatures_Referential Cohesion - Std.Dev._0, scalarFeatures_Sentence Length (in Tokens) - Mean_0, scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0, scalarFeatures_Subordinate Ratio - Mean_0, scalarFeatures_Subordinate Ratio - Std.Dev._0, scalarFeatures_Text Length (in Lemmas)_0, scalarFeatures_Text Length (in Sentences)_0, scalarFeatures_Token Length - Mean_0, scalarFeatures_Token Length - Std.Dev._0, scalarFeatures_Verbal Roots_0, simpleScalarFeatures_Lunghezza del testo_0, simpleScalarFeatures_Lunghezza media delle frasi_0, simpleScalarFeatures_Varietà lessicale_0, distrFeatures_Arity of Verbal Predicates_ 0 _0, distrFeatures_Arity of Verbal Predicates_ 1 _0, distrFeatures_Arity of Verbal Predicates_ 2 _0, distrFeatures_Arity of Verbal Predicates_ 3 _0, distrFeatures_Arity of Verbal Predicates_ 4 _0, distrFeatures_Arity of Verbal Predicates_Std.Dev._0, distrFeatures_Arity of Verbal Predicates_≥ 5_0, distrFeatures_Basic Vucabulary Rate_Fundamentals_0, distrFeatures_Basic Vucabulary Rate_High Availability_0, distrFeatures_Basic Vucabulary Rate_High Usage_0, distrFeatures_Deep Causal Cohesion_Entropy_0, distrFeatures_Deep Causal Cohesion_additive_0, distrFeatures_Deep Causal Cohesion_adversative_0, distrFeatures_Deep Causal Cohesion_alternative_0, distrFeatures_Deep Causal Cohesion_causal_0, distrFeatures_Deep Causal Cohesion_marking results_0, distrFeatures_Deep Causal Cohesion_reformulation_0, distrFeatures_Deep Causal Cohesion_temporal_0, distrFeatures_Deep Causal Cohesion_transitions_0, distrFeatures_Dependency Links Length_Max_0, distrFeatures_Dependency Links Length_Mean_0, distrFeatures_Dependency Links Length_Std.Dev._0, distrFeatures_Dependency Tags Distribution_Entropy_0, distrFeatures_Dependency Tags Distribution_acl_0, distrFeatures_Dependency Tags Distribution_advcl_0, distrFeatures_Dependency Tags Distribution_advmod_0, distrFeatures_Dependency Tags Distribution_amod_0, distrFeatures_Dependency Tags Distribution_appos_0, distrFeatures_Dependency Tags Distribution_aux_0, distrFeatures_Dependency Tags Distribution_case_0, distrFeatures_Dependency Tags Distribution_cc_0, distrFeatures_Dependency Tags Distribution_ccomp_0, distrFeatures_Dependency Tags Distribution_compound_0, distrFeatures_Dependency Tags Distribution_conj_0, distrFeatures_Dependency Tags Distribution_cop_0, distrFeatures_Dependency Tags Distribution_csubj_0, distrFeatures_Dependency Tags Distribution_det_0, distrFeatures_Dependency Tags Distribution_discourse_0, distrFeatures_Dependency Tags Distribution_dislocated_0, distrFeatures_Dependency Tags Distribution_expl_0, distrFeatures_Dependency Tags Distribution_fixed_0, distrFeatures_Dependency Tags Distribution_flat_0, distrFeatures_Dependency Tags Distribution_iobj_0, distrFeatures_Dependency Tags Distribution_mark_0, distrFeatures_Dependency Tags Distribution_nmod_0, distrFeatures_Dependency Tags Distribution_nsubj_0, distrFeatures_Dependency Tags Distribution_nummod_0, distrFeatures_Dependency Tags Distribution_obj_0, distrFeatures_Dependency Tags Distribution_obl_0, distrFeatures_Dependency Tags Distribution_parataxis_0, distrFeatures_Dependency Tags Distribution_punct_0, distrFeatures_Dependency Tags Distribution_root_0, distrFeatures_Dependency Tags Distribution_vocative_0, distrFeatures_Dependency Tags Distribution_xcomp_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0, distrFeatures_Lexical Variation Feature_Adj A_0, distrFeatures_Lexical Variation Feature_Adj B_0, distrFeatures_Lexical Variation Feature_Adv A_0, distrFeatures_Lexical Variation Feature_Adv B_0, distrFeatures_Lexical Variation Feature_Noun A_0, distrFeatures_Lexical Variation Feature_Noun B_0, distrFeatures_Lexical Variation Feature_Verb A_0, distrFeatures_Lexical Variation Feature_Verb B_0, distrFeatures_MCI (Morphological Complexity Index)_Nouns_0, distrFeatures_MCI (Morphological Complexity Index)_Verbs_0, distrFeatures_Nouns Abstractness Distribution_Abstract_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 157 columns]\n",
      "#\n",
      "    essay predicted  probability_B1  probability_B2  probability_C1   \n",
      "0    0507         1        0.517577        0.327451        0.154971  \\\n",
      "1    0530         1        0.500454        0.352201        0.147345   \n",
      "2    1294         2        0.158926        0.516177        0.324896   \n",
      "3    1616         1        0.512450        0.332827        0.154723   \n",
      "4    1716         1        0.517272        0.327845        0.154883   \n",
      "..    ...       ...             ...             ...             ...   \n",
      "834  5405         1        0.500719        0.342517        0.156764   \n",
      "835  5406         1        0.497574        0.332617        0.169809   \n",
      "836  5407         1        0.506108        0.336022        0.157870   \n",
      "837  5408         1        0.512657        0.332010        0.155333   \n",
      "838  5409         1        0.492617        0.372067        0.135316   \n",
      "\n",
      "     probability_C2  scalarFeatures_Depth of the Parse Trees_0   \n",
      "0               0.0                                       20.0  \\\n",
      "1               0.0                                        8.0   \n",
      "2               0.0                                       13.0   \n",
      "3               0.0                                        7.0   \n",
      "4               0.0                                       15.0   \n",
      "..              ...                                        ...   \n",
      "834             0.0                                        8.0   \n",
      "835             0.0                                       14.0   \n",
      "836             0.0                                       13.0   \n",
      "837             0.0                                       13.0   \n",
      "838             0.0                                       13.0   \n",
      "\n",
      "     scalarFeatures_Lexical Diversity_0   \n",
      "0                               0.41971  \\\n",
      "1                               0.37606   \n",
      "2                               0.41030   \n",
      "3                               0.37677   \n",
      "4                               0.41558   \n",
      "..                                  ...   \n",
      "834                             0.34402   \n",
      "835                             0.38453   \n",
      "836                             0.40669   \n",
      "837                             0.42699   \n",
      "838                             0.37258   \n",
      "\n",
      "     scalarFeatures_Maximal Non-Verbal Phrase - Mean_0   \n",
      "0                                            25.444445  \\\n",
      "1                                             8.153846   \n",
      "2                                             6.642857   \n",
      "3                                             7.285714   \n",
      "4                                             8.000000   \n",
      "..                                                 ...   \n",
      "834                                           5.086957   \n",
      "835                                          10.214286   \n",
      "836                                          18.500000   \n",
      "837                                          11.000000   \n",
      "838                                           6.730769   \n",
      "\n",
      "     scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0  ...   \n",
      "0                                            43.104847      ...  \\\n",
      "1                                             5.942028      ...   \n",
      "2                                             4.415581      ...   \n",
      "3                                             6.210590      ...   \n",
      "4                                             8.426149      ...   \n",
      "..                                                 ...      ...   \n",
      "834                                           5.273545      ...   \n",
      "835                                           8.154079      ...   \n",
      "836                                          26.213863      ...   \n",
      "837                                          12.961481      ...   \n",
      "838                                          10.535872      ...   \n",
      "\n",
      "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Astrattezza_0   \n",
      "0                                             0.070175                             \\\n",
      "1                                             0.049180                              \n",
      "2                                             0.100000                              \n",
      "3                                             0.062500                              \n",
      "4                                             0.125000                              \n",
      "..                                                 ...                              \n",
      "834                                           0.015625                              \n",
      "835                                           0.019608                              \n",
      "836                                           0.102041                              \n",
      "837                                           0.024390                              \n",
      "838                                           0.245283                              \n",
      "\n",
      "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Semiastrattezza_0   \n",
      "0                                             0.280702                                 \\\n",
      "1                                             0.409836                                  \n",
      "2                                             0.309091                                  \n",
      "3                                             0.375000                                  \n",
      "4                                             0.156250                                  \n",
      "..                                                 ...                                  \n",
      "834                                           0.421875                                  \n",
      "835                                           0.568627                                  \n",
      "836                                           0.285714                                  \n",
      "837                                           0.243902                                  \n",
      "838                                           0.433962                                  \n",
      "\n",
      "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Concretezza_0   \n",
      "0                                             0.649123                             \\\n",
      "1                                             0.540984                              \n",
      "2                                             0.590909                              \n",
      "3                                             0.562500                              \n",
      "4                                             0.718750                              \n",
      "..                                                 ...                              \n",
      "834                                           0.562500                              \n",
      "835                                           0.411765                              \n",
      "836                                           0.612245                              \n",
      "837                                           0.731707                              \n",
      "838                                           0.320755                              \n",
      "\n",
      "     simpleDistrFeatures_Sofisticatezza lessicale_parole vuote_0   \n",
      "0                                             0.013650            \\\n",
      "1                                             0.010836             \n",
      "2                                             0.015028             \n",
      "3                                             0.011760             \n",
      "4                                             0.009433             \n",
      "..                                                 ...             \n",
      "834                                           0.011452             \n",
      "835                                           0.012934             \n",
      "836                                           0.013077             \n",
      "837                                           0.011434             \n",
      "838                                           0.011495             \n",
      "\n",
      "     simpleDistrFeatures_Sofisticatezza lessicale_lemmi vuoti_0   \n",
      "0                                             0.012983           \\\n",
      "1                                             0.011133            \n",
      "2                                             0.010181            \n",
      "3                                             0.018896            \n",
      "4                                             0.014928            \n",
      "..                                                 ...            \n",
      "834                                           0.010991            \n",
      "835                                           0.010871            \n",
      "836                                           0.015657            \n",
      "837                                           0.011977            \n",
      "838                                           0.009185            \n",
      "\n",
      "     simpleDistrFeatures_Sofisticatezza lessicale_parole contenuto_0   \n",
      "0                                             0.000428                \\\n",
      "1                                             0.000420                 \n",
      "2                                             0.000399                 \n",
      "3                                             0.000424                 \n",
      "4                                             0.000618                 \n",
      "..                                                 ...                 \n",
      "834                                           0.000838                 \n",
      "835                                           0.000540                 \n",
      "836                                           0.000852                 \n",
      "837                                           0.000403                 \n",
      "838                                           0.001072                 \n",
      "\n",
      "     simpleDistrFeatures_Sofisticatezza lessicale_lemmi contenuto_0   \n",
      "0                                             0.000510               \\\n",
      "1                                             0.000600                \n",
      "2                                             0.000382                \n",
      "3                                             0.000757                \n",
      "4                                             0.000914                \n",
      "..                                                 ...                \n",
      "834                                           0.000606                \n",
      "835                                           0.000793                \n",
      "836                                           0.000547                \n",
      "837                                           0.000467                \n",
      "838                                           0.000590                \n",
      "\n",
      "     simpleDistrFeatures_Tasso di vocabolario di base_Fondamentali_0   \n",
      "0                                             0.878261                \\\n",
      "1                                             0.913043                 \n",
      "2                                             0.847458                 \n",
      "3                                             0.873016                 \n",
      "4                                             0.876543                 \n",
      "..                                                 ...                 \n",
      "834                                           0.927007                 \n",
      "835                                           0.942857                 \n",
      "836                                           0.833333                 \n",
      "837                                           0.846847                 \n",
      "838                                           0.905660                 \n",
      "\n",
      "     simpleDistrFeatures_Tasso di vocabolario di base_Alto uso_0   \n",
      "0                                             0.113043            \\\n",
      "1                                             0.052174             \n",
      "2                                             0.135593             \n",
      "3                                             0.111111             \n",
      "4                                             0.111111             \n",
      "..                                                 ...             \n",
      "834                                           0.058394             \n",
      "835                                           0.057143             \n",
      "836                                           0.129630             \n",
      "837                                           0.135135             \n",
      "838                                           0.069182             \n",
      "\n",
      "     simpleDistrFeatures_Tasso di vocabolario di base_Alto disponibilità_0  \n",
      "0                                             0.008696                      \n",
      "1                                             0.034783                      \n",
      "2                                             0.016949                      \n",
      "3                                             0.015873                      \n",
      "4                                             0.012346                      \n",
      "..                                                 ...                      \n",
      "834                                           0.014599                      \n",
      "835                                           0.000000                      \n",
      "836                                           0.037037                      \n",
      "837                                           0.018018                      \n",
      "838                                           0.025157                      \n",
      "\n",
      "[839 rows x 157 columns]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dtypes = defaultdict(np.float32, fn='str', predicted='category')\n",
    "\n",
    "training_cita_malt = data_prefix + '/interim/LangLearn_Training_Data/CItA/malt.csv'\n",
    "\n",
    "df_malt = pd.read_csv(training_cita_malt, sep=',', dtype=dtypes, keep_default_na=False)\n",
    "df_malt['predicted'].replace(['B1', 'B2', 'C1', 'C2'], [1,2,3,4], inplace=True)\n",
    "df_malt['predicted'] = df_malt['predicted'].astype(pd.CategoricalDtype(ordered=True))\n",
    "df_malt.rename(columns={\"fn\":\"essay\"}, inplace=True)\n",
    "df_malt['essay'] = df_malt['essay'].str.replace('.txt','')\n",
    "df_malt.sort_values('essay', inplace=True, ignore_index=True)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "df_malt_vt = VarianceThreshold().set_output(transform='pandas')\n",
    "df_malt_numbers = df_malt.select_dtypes('number').copy()\n",
    "df_malt.drop(columns=df_malt_numbers.columns, inplace=True)\n",
    "df_malt = pd.concat([df_malt, df_malt_vt.fit_transform(df_malt_numbers)], axis=1)\n",
    "\n",
    "print(df_malt[df_malt.isna().any(axis=1)])\n",
    "print(df_malt[df_malt.isnull().any(axis=1)])\n",
    "print(\"#\")\n",
    "print(df_malt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple vuole comprare una startup del Regno Unito per un miliardo di dollari\n",
      "Apple Apple PROPN  nsubj\n",
      "vuole volere AUX Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin aux\n",
      "comprare comprare VERB VerbForm=Inf ROOT\n",
      "una uno DET Definite=Ind|Gender=Fem|Number=Sing|PronType=Art det\n",
      "startup startup NOUN Gender=Fem|Number=Sing obj\n",
      "del di il ADP Definite=Def|Gender=Masc|Number=Sing|PronType=Art case\n",
      "Regno Regno PROPN  nmod\n",
      "Unito Unito PROPN  flat:name\n",
      "per per ADP  case\n",
      "un uno DET Definite=Ind|Gender=Masc|Number=Sing|PronType=Art det\n",
      "miliardo miliardo NOUN Gender=Masc|Number=Sing obl\n",
      "di di ADP  case\n",
      "dollari dollaro NOUN Gender=Masc|Number=Plur nmod\n"
     ]
    }
   ],
   "source": [
    "# spaCy - IT\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.it.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"it_core_news_lg\")\n",
    "doc = nlp(sentences[0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.morph, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"it_core_news_lg\")\n",
    "\n",
    "import langlearn.dataprep.utils\n",
    "training_cita_essays_fn = data_prefix + '/interim/LangLearn_Training_Data/CItA/Essays_CItA.xml'\n",
    "txts = langlearn.dataprep.utils.get_txts(training_cita_essays_fn, shrink_whitespaces=True)\n",
    "docs = dict(zip(list(txts.keys()), list(nlp.pipe(list(txts.values())))))\n",
    "\n",
    "testing_cita_essays_fn = data_prefix + '/interim/LangLearn_Test_Data/CItA/Essays_Test_CItA.xml'\n",
    "txts_test = langlearn.dataprep.utils.get_txts(testing_cita_essays_fn, shrink_whitespaces=True)\n",
    "docs.update(dict(zip(list(txts_test.keys()), list(nlp.pipe(list(txts_test.values()))))))\n",
    "\n",
    "#list(txts.keys())\n",
    "# ['9843',\n",
    "# '7432',\n",
    "# '2512',\n",
    "# '3156',\n",
    "# ...\n",
    "\n",
    "#list(docs.items())\n",
    "#[('9843',\n",
    "#  Cuando pienso sobre una persona especial en mi vida, ...),\n",
    "# ('7432',\n",
    "#  Mi novia es muy importante en mi vida. Ella es muy ...),\n",
    "# ('2512',\n",
    "# ...\n",
    "\n",
    "#type(list(docs.values())[0])\n",
    "# spacy.tokens.doc.Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5076\n",
      "4523\n",
      "4951\n",
      "4626\n",
      "5113\n",
      "5321\n",
      "5306\n",
      "5169\n",
      "5329\n",
      "4736\n",
      "4962\n",
      "5320\n",
      "2697\n",
      "5021\n",
      "5275\n",
      "3291\n",
      "3527\n",
      "4375\n",
      "5030\n",
      "5161\n",
      "4825\n",
      "4473\n",
      "4958\n",
      "5224\n",
      "3375\n",
      "3986\n",
      "5056\n",
      "1942\n",
      "4916\n",
      "4655\n",
      "4552\n",
      "5397\n",
      "4907\n",
      "5340\n",
      "4450\n",
      "4884\n",
      "5101\n",
      "5287\n",
      "5244\n",
      "4607\n",
      "5004\n",
      "4515\n",
      "4285\n",
      "5053\n",
      "4323\n",
      "4388\n",
      "5245\n",
      "3863\n",
      "4434\n",
      "4325\n",
      "5203\n",
      "4348\n",
      "4748\n",
      "3407\n",
      "3354\n",
      "3740\n",
      "4219\n",
      "2068\n",
      "4541\n",
      "5353\n",
      "4272\n",
      "4793\n",
      "5391\n",
      "5371\n",
      "2339\n",
      "4455\n",
      "5310\n",
      "4987\n",
      "5090\n",
      "4215\n",
      "5235\n",
      "4922\n",
      "4934\n",
      "3159\n",
      "5095\n",
      "4411\n",
      "5230\n",
      "5234\n",
      "4889\n",
      "4945\n",
      "4622\n",
      "5312\n",
      "4906\n",
      "5335\n",
      "5159\n",
      "5128\n",
      "4860\n",
      "5326\n",
      "4852\n",
      "4502\n",
      "5045\n",
      "4600\n",
      "4319\n",
      "5211\n",
      "4940\n",
      "4653\n",
      "4661\n",
      "3886\n",
      "3572\n",
      "5345\n",
      "5251\n",
      "4715\n",
      "5102\n",
      "3342\n",
      "5404\n",
      "4560\n",
      "5033\n",
      "3383\n",
      "4431\n",
      "4759\n",
      "4810\n",
      "4608\n",
      "4666\n",
      "3925\n",
      "5031\n",
      "3960\n",
      "5398\n",
      "5314\n",
      "5249\n",
      "4447\n",
      "4876\n",
      "5044\n",
      "5156\n",
      "5387\n",
      "4472\n",
      "5085\n",
      "5020\n",
      "4920\n",
      "4317\n",
      "4953\n",
      "5149\n",
      "4519\n",
      "3989\n",
      "3950\n",
      "4251\n",
      "3678\n",
      "5065\n",
      "4800\n",
      "2836\n",
      "5097\n",
      "3728\n",
      "4888\n",
      "4077\n",
      "5166\n",
      "5394\n",
      "5115\n",
      "4509\n",
      "4694\n",
      "4872\n",
      "4965\n",
      "5274\n",
      "5195\n",
      "5187\n",
      "4952\n",
      "4152\n",
      "4689\n",
      "5355\n",
      "4773\n",
      "5150\n",
      "4576\n",
      "4526\n",
      "4514\n",
      "4938\n",
      "3541\n",
      "4559\n",
      "3877\n",
      "3813\n",
      "5077\n",
      "5378\n",
      "5277\n",
      "5229\n",
      "5280\n",
      "3498\n",
      "2118\n",
      "5343\n",
      "4281\n",
      "5068\n",
      "4465\n",
      "4755\n",
      "4564\n",
      "4445\n",
      "4767\n",
      "4745\n",
      "5262\n",
      "4913\n",
      "4024\n",
      "2584\n",
      "4750\n",
      "4154\n",
      "5311\n",
      "4359\n",
      "4879\n",
      "4983\n",
      "5257\n",
      "5384\n",
      "4606\n",
      "4874\n",
      "4019\n",
      "4667\n",
      "3926\n",
      "5133\n",
      "4917\n",
      "5106\n",
      "4648\n",
      "5205\n",
      "3471\n",
      "5201\n",
      "5276\n",
      "4288\n",
      "5339\n",
      "4921\n",
      "5383\n",
      "4477\n",
      "4565\n",
      "4427\n",
      "4300\n",
      "5168\n",
      "3665\n",
      "5130\n",
      "4869\n",
      "5043\n",
      "4697\n",
      "5333\n",
      "5346\n",
      "4453\n",
      "4677\n",
      "4839\n",
      "4433\n",
      "4596\n",
      "5360\n",
      "5317\n",
      "4744\n",
      "5247\n",
      "5006\n",
      "4235\n",
      "4364\n",
      "5072\n",
      "4722\n",
      "4230\n",
      "3966\n"
     ]
    }
   ],
   "source": [
    "for key in set(txts).intersection(set(txts_test)):\n",
    "    if key in ['5034']:\n",
    "        continue\n",
    "    print(key)\n",
    "    assert txts[key] == txts_test[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from langlearn.dataprep.transformers import SpacyDocsPreprocessor\n",
    "\n",
    "spacy_wf = Pipeline([\n",
    "  ('wordform', SpacyDocsPreprocessor(docs=docs)),\n",
    "  (\"count\", CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    preprocessor=lambda x: [tok.strip() for tok in x],\n",
    "    lowercase=False,\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 3),\n",
    "    min_df = 5,\n",
    "    #min_df = 0.15,\n",
    "    # max_features=500\n",
    "  ))\n",
    "], verbose=True)\n",
    "\n",
    "spacy_lem = Pipeline([\n",
    "  ('lemma', SpacyDocsPreprocessor(docs=docs, token_attribute='lemma_')),\n",
    "  (\"count\", CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    preprocessor=lambda x: x,\n",
    "    lowercase=False,\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 3),\n",
    "    min_df = 5,\n",
    "    #min_df = 0.2,\n",
    "    #max_features=500\n",
    "  ))\n",
    "], verbose=True)\n",
    "\n",
    "spacy_pos = Pipeline([\n",
    "  ('pos', SpacyDocsPreprocessor(docs=docs, token_attribute='pos_')),\n",
    "  (\"count\", CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    preprocessor=lambda x: x,\n",
    "    lowercase=False,\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 3),\n",
    "    min_df = 5,\n",
    "    #min_df = 0.15,\n",
    "    # max_features=500\n",
    "  ))\n",
    "], verbose=True)\n",
    "\n",
    "spacy_dep = Pipeline([\n",
    "  ('dep', SpacyDocsPreprocessor(docs=docs, token_attribute=None)),\n",
    "  (\"count\", CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    preprocessor=lambda x: [f\"{tok.dep_} {tok.head.dep_}\" for tok in x],\n",
    "    lowercase=False,\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "  ))\n",
    "], verbose=True)\n",
    "\n",
    "spacy_morph = Pipeline([\n",
    "  ('morph', SpacyDocsPreprocessor(docs=docs, token_attribute='morph')),\n",
    "  (\"count\", CountVectorizer(\n",
    "    token_pattern=r\"\\b[,=\\w]+\\b\",\n",
    "    preprocessor=lambda x: str([' '.join(str(tok).split('|')) for tok in x]),\n",
    "    lowercase=False,\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 2),\n",
    "  ))\n",
    "], verbose=True)\n",
    "\n",
    "#res = spacy_wf.fit_transform(docs.keys())\n",
    "#for feature in spacy_wf.get_feature_names_out()[0:150]:\n",
    "#  print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     author essay  sequence_abs\n",
      "0    A_3375  4355             0\n",
      "1    A_3375  3375             1\n",
      "2    A_3375  4466             2\n",
      "3    A_3375  5217             3\n",
      "4    A_3375  5310             4\n",
      "..      ...   ...           ...\n",
      "834  A_4314  4613             7\n",
      "835  A_4314  4314             8\n",
      "836  A_4131  4216             7\n",
      "837  A_4131  4850             9\n",
      "838  A_4131  4131             9\n",
      "\n",
      "[839 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ciao!!!\n",
       "Il mio cantante preferito si chiama Justin Bibler , ma non ho mai visto un suo concerto dal vivo. \n",
       "Mi chiamo Gaia, ho undici anni compiuti il primo Ottobre e frequento la prima media della scuola “Sant’Agata dei Goti”. Per quattro anni, non abitando nel “Centro storico” di Roma ho frequentato la scuola “Europa” nel plesso “Carlo Alberto Dalla Chiesa”. Mentre l’ultimo anno della scuola primaria sono stata nella scuola “Luigi Settembrini” del plesso “E. Q. Visconti”. Credo di essere molto preparata per poi affrontare ogni tipo di esame nella scuola secondaria. Da grande, vorrei diventare una ginecologa laureandomi in medicina dopo cinque anni del liceo classico. Mi piace molto la scuola perché ci si socializza con persone nuove e si imparano molte cose istruttive. La mia materia preferita è l’italiano, la storia e la scienze. Adoro lo sport, in particolare il nuoto e la pallavvolo. Come attività extrascolastiche pratico il nuoto il lunedì, martedì e venerdì. Il giovedì vado con la scuola a svolgere la pallavvolo e il mercoledì, il sabato e la domenica mi riposo. La mia famiglia è composta da me, mio fratello, mia madre e mio padre. Mio fratello si chiama Luca, mia madre si chiama Mariaelena e mio padre Marco. Mamma lavora in una società telefonica e papà è un carabiniere e, come mia mamma, si è laureato per due volte. Vivo in una caserma dei carabinieri (dove lavora mio padre) con un giardino splendido e una casa molto spaziosa.\n",
       "Nel giardino c’è una fontana con i pesci, una fontanella per bere, una cupoletta con la Madonna e un giardinetto in terra coltivabile. Ho una tartaruga di nome “Pizzicotto” e, nel mio tempo libero ci gioco molto. Mi piace molto leggere libri soprattutto gli umor e i grandi “classici”. Ho una migliore amica di nome Olivia ed è come una sorella per me. Ogni estate vado dai miei nonni con lei e ci troviamo sempre una nostra amica di nome Gilda e, con lei, ci divertiamo sempre.\n",
       "Sono molto felice di essermi presentata!!!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df)\n",
    "docs['4355']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author, essay, sequence_abs, predicted, probability_B1, probability_B2, probability_C1, probability_C2, scalarFeatures_Depth of the Parse Trees_0, scalarFeatures_Lexical Diversity_0, scalarFeatures_Maximal Non-Verbal Phrase - Mean_0, scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0, scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0, scalarFeatures_Non-Verbal Chains Length - Mean_0, scalarFeatures_Non-Verbal Chains Length - Std.Dev._0, scalarFeatures_Referential Cohesion - Mean_0, scalarFeatures_Referential Cohesion - Std.Dev._0, scalarFeatures_Sentence Length (in Tokens) - Mean_0, scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0, scalarFeatures_Subordinate Ratio - Mean_0, scalarFeatures_Subordinate Ratio - Std.Dev._0, scalarFeatures_Text Length (in Lemmas)_0, scalarFeatures_Text Length (in Sentences)_0, scalarFeatures_Token Length - Mean_0, scalarFeatures_Token Length - Std.Dev._0, scalarFeatures_Verbal Roots_0, simpleScalarFeatures_Lunghezza del testo_0, simpleScalarFeatures_Lunghezza media delle frasi_0, simpleScalarFeatures_Varietà lessicale_0, distrFeatures_Arity of Verbal Predicates_ 0 _0, distrFeatures_Arity of Verbal Predicates_ 1 _0, distrFeatures_Arity of Verbal Predicates_ 2 _0, distrFeatures_Arity of Verbal Predicates_ 3 _0, distrFeatures_Arity of Verbal Predicates_ 4 _0, distrFeatures_Arity of Verbal Predicates_Std.Dev._0, distrFeatures_Arity of Verbal Predicates_≥ 5_0, distrFeatures_Basic Vucabulary Rate_Fundamentals_0, distrFeatures_Basic Vucabulary Rate_High Availability_0, distrFeatures_Basic Vucabulary Rate_High Usage_0, distrFeatures_Deep Causal Cohesion_Entropy_0, distrFeatures_Deep Causal Cohesion_additive_0, distrFeatures_Deep Causal Cohesion_adversative_0, distrFeatures_Deep Causal Cohesion_alternative_0, distrFeatures_Deep Causal Cohesion_causal_0, distrFeatures_Deep Causal Cohesion_marking results_0, distrFeatures_Deep Causal Cohesion_reformulation_0, distrFeatures_Deep Causal Cohesion_temporal_0, distrFeatures_Deep Causal Cohesion_transitions_0, distrFeatures_Dependency Links Length_Max_0, distrFeatures_Dependency Links Length_Mean_0, distrFeatures_Dependency Links Length_Std.Dev._0, distrFeatures_Dependency Tags Distribution_Entropy_0, distrFeatures_Dependency Tags Distribution_acl_0, distrFeatures_Dependency Tags Distribution_advcl_0, distrFeatures_Dependency Tags Distribution_advmod_0, distrFeatures_Dependency Tags Distribution_amod_0, distrFeatures_Dependency Tags Distribution_appos_0, distrFeatures_Dependency Tags Distribution_aux_0, distrFeatures_Dependency Tags Distribution_case_0, distrFeatures_Dependency Tags Distribution_cc_0, distrFeatures_Dependency Tags Distribution_ccomp_0, distrFeatures_Dependency Tags Distribution_compound_0, distrFeatures_Dependency Tags Distribution_conj_0, distrFeatures_Dependency Tags Distribution_cop_0, distrFeatures_Dependency Tags Distribution_csubj_0, distrFeatures_Dependency Tags Distribution_det_0, distrFeatures_Dependency Tags Distribution_discourse_0, distrFeatures_Dependency Tags Distribution_dislocated_0, distrFeatures_Dependency Tags Distribution_expl_0, distrFeatures_Dependency Tags Distribution_fixed_0, distrFeatures_Dependency Tags Distribution_flat_0, distrFeatures_Dependency Tags Distribution_iobj_0, distrFeatures_Dependency Tags Distribution_mark_0, distrFeatures_Dependency Tags Distribution_nmod_0, distrFeatures_Dependency Tags Distribution_nsubj_0, distrFeatures_Dependency Tags Distribution_nummod_0, distrFeatures_Dependency Tags Distribution_obj_0, distrFeatures_Dependency Tags Distribution_obl_0, distrFeatures_Dependency Tags Distribution_parataxis_0, distrFeatures_Dependency Tags Distribution_punct_0, distrFeatures_Dependency Tags Distribution_root_0, distrFeatures_Dependency Tags Distribution_vocative_0, distrFeatures_Dependency Tags Distribution_xcomp_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0, distrFeatures_Lexical Variation Feature_Adj A_0, distrFeatures_Lexical Variation Feature_Adj B_0, distrFeatures_Lexical Variation Feature_Adv A_0, distrFeatures_Lexical Variation Feature_Adv B_0, distrFeatures_Lexical Variation Feature_Noun A_0, distrFeatures_Lexical Variation Feature_Noun B_0, distrFeatures_Lexical Variation Feature_Verb A_0, distrFeatures_Lexical Variation Feature_Verb B_0, distrFeatures_MCI (Morphological Complexity Index)_Nouns_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 159 columns]\n",
      "Empty DataFrame\n",
      "Columns: [author, essay, sequence_abs, predicted, probability_B1, probability_B2, probability_C1, probability_C2, scalarFeatures_Depth of the Parse Trees_0, scalarFeatures_Lexical Diversity_0, scalarFeatures_Maximal Non-Verbal Phrase - Mean_0, scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0, scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0, scalarFeatures_Non-Verbal Chains Length - Mean_0, scalarFeatures_Non-Verbal Chains Length - Std.Dev._0, scalarFeatures_Referential Cohesion - Mean_0, scalarFeatures_Referential Cohesion - Std.Dev._0, scalarFeatures_Sentence Length (in Tokens) - Mean_0, scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0, scalarFeatures_Subordinate Ratio - Mean_0, scalarFeatures_Subordinate Ratio - Std.Dev._0, scalarFeatures_Text Length (in Lemmas)_0, scalarFeatures_Text Length (in Sentences)_0, scalarFeatures_Token Length - Mean_0, scalarFeatures_Token Length - Std.Dev._0, scalarFeatures_Verbal Roots_0, simpleScalarFeatures_Lunghezza del testo_0, simpleScalarFeatures_Lunghezza media delle frasi_0, simpleScalarFeatures_Varietà lessicale_0, distrFeatures_Arity of Verbal Predicates_ 0 _0, distrFeatures_Arity of Verbal Predicates_ 1 _0, distrFeatures_Arity of Verbal Predicates_ 2 _0, distrFeatures_Arity of Verbal Predicates_ 3 _0, distrFeatures_Arity of Verbal Predicates_ 4 _0, distrFeatures_Arity of Verbal Predicates_Std.Dev._0, distrFeatures_Arity of Verbal Predicates_≥ 5_0, distrFeatures_Basic Vucabulary Rate_Fundamentals_0, distrFeatures_Basic Vucabulary Rate_High Availability_0, distrFeatures_Basic Vucabulary Rate_High Usage_0, distrFeatures_Deep Causal Cohesion_Entropy_0, distrFeatures_Deep Causal Cohesion_additive_0, distrFeatures_Deep Causal Cohesion_adversative_0, distrFeatures_Deep Causal Cohesion_alternative_0, distrFeatures_Deep Causal Cohesion_causal_0, distrFeatures_Deep Causal Cohesion_marking results_0, distrFeatures_Deep Causal Cohesion_reformulation_0, distrFeatures_Deep Causal Cohesion_temporal_0, distrFeatures_Deep Causal Cohesion_transitions_0, distrFeatures_Dependency Links Length_Max_0, distrFeatures_Dependency Links Length_Mean_0, distrFeatures_Dependency Links Length_Std.Dev._0, distrFeatures_Dependency Tags Distribution_Entropy_0, distrFeatures_Dependency Tags Distribution_acl_0, distrFeatures_Dependency Tags Distribution_advcl_0, distrFeatures_Dependency Tags Distribution_advmod_0, distrFeatures_Dependency Tags Distribution_amod_0, distrFeatures_Dependency Tags Distribution_appos_0, distrFeatures_Dependency Tags Distribution_aux_0, distrFeatures_Dependency Tags Distribution_case_0, distrFeatures_Dependency Tags Distribution_cc_0, distrFeatures_Dependency Tags Distribution_ccomp_0, distrFeatures_Dependency Tags Distribution_compound_0, distrFeatures_Dependency Tags Distribution_conj_0, distrFeatures_Dependency Tags Distribution_cop_0, distrFeatures_Dependency Tags Distribution_csubj_0, distrFeatures_Dependency Tags Distribution_det_0, distrFeatures_Dependency Tags Distribution_discourse_0, distrFeatures_Dependency Tags Distribution_dislocated_0, distrFeatures_Dependency Tags Distribution_expl_0, distrFeatures_Dependency Tags Distribution_fixed_0, distrFeatures_Dependency Tags Distribution_flat_0, distrFeatures_Dependency Tags Distribution_iobj_0, distrFeatures_Dependency Tags Distribution_mark_0, distrFeatures_Dependency Tags Distribution_nmod_0, distrFeatures_Dependency Tags Distribution_nsubj_0, distrFeatures_Dependency Tags Distribution_nummod_0, distrFeatures_Dependency Tags Distribution_obj_0, distrFeatures_Dependency Tags Distribution_obl_0, distrFeatures_Dependency Tags Distribution_parataxis_0, distrFeatures_Dependency Tags Distribution_punct_0, distrFeatures_Dependency Tags Distribution_root_0, distrFeatures_Dependency Tags Distribution_vocative_0, distrFeatures_Dependency Tags Distribution_xcomp_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0, distrFeatures_Lexical Variation Feature_Adj A_0, distrFeatures_Lexical Variation Feature_Adj B_0, distrFeatures_Lexical Variation Feature_Adv A_0, distrFeatures_Lexical Variation Feature_Adv B_0, distrFeatures_Lexical Variation Feature_Noun A_0, distrFeatures_Lexical Variation Feature_Noun B_0, distrFeatures_Lexical Variation Feature_Verb A_0, distrFeatures_Lexical Variation Feature_Verb B_0, distrFeatures_MCI (Morphological Complexity Index)_Nouns_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 159 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>essay</th>\n",
       "      <th>sequence_abs</th>\n",
       "      <th>predicted</th>\n",
       "      <th>probability_B1</th>\n",
       "      <th>probability_B2</th>\n",
       "      <th>probability_C1</th>\n",
       "      <th>probability_C2</th>\n",
       "      <th>scalarFeatures_Depth of the Parse Trees_0</th>\n",
       "      <th>scalarFeatures_Lexical Diversity_0</th>\n",
       "      <th>...</th>\n",
       "      <th>simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Astrattezza_0</th>\n",
       "      <th>simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Semiastrattezza_0</th>\n",
       "      <th>simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Concretezza_0</th>\n",
       "      <th>simpleDistrFeatures_Sofisticatezza lessicale_parole vuote_0</th>\n",
       "      <th>simpleDistrFeatures_Sofisticatezza lessicale_lemmi vuoti_0</th>\n",
       "      <th>simpleDistrFeatures_Sofisticatezza lessicale_parole contenuto_0</th>\n",
       "      <th>simpleDistrFeatures_Sofisticatezza lessicale_lemmi contenuto_0</th>\n",
       "      <th>simpleDistrFeatures_Tasso di vocabolario di base_Fondamentali_0</th>\n",
       "      <th>simpleDistrFeatures_Tasso di vocabolario di base_Alto uso_0</th>\n",
       "      <th>simpleDistrFeatures_Tasso di vocabolario di base_Alto disponibilità_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>4355</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506112</td>\n",
       "      <td>0.349380</td>\n",
       "      <td>0.144508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.402510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.316456</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>0.015009</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.114504</td>\n",
       "      <td>0.030534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>3375</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.325794</td>\n",
       "      <td>0.511743</td>\n",
       "      <td>0.162462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.383010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>4466</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.347513</td>\n",
       "      <td>0.491908</td>\n",
       "      <td>0.160579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.376060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>0.011012</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.056452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>5217</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494528</td>\n",
       "      <td>0.348384</td>\n",
       "      <td>0.157088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.392630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.011711</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.940678</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.008475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_3375</td>\n",
       "      <td>5310</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.182036</td>\n",
       "      <td>0.484657</td>\n",
       "      <td>0.333307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.012638</td>\n",
       "      <td>0.010282</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>A_4314</td>\n",
       "      <td>4613</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029305</td>\n",
       "      <td>0.463089</td>\n",
       "      <td>0.507606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.417210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.016484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>A_4314</td>\n",
       "      <td>4314</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516822</td>\n",
       "      <td>0.327856</td>\n",
       "      <td>0.155322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.436890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.716763</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.150794</td>\n",
       "      <td>0.031746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>A_4131</td>\n",
       "      <td>4216</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.517918</td>\n",
       "      <td>0.327224</td>\n",
       "      <td>0.154858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.385330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.014866</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>A_4131</td>\n",
       "      <td>4131</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518043</td>\n",
       "      <td>0.327208</td>\n",
       "      <td>0.154750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.015770</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>A_4131</td>\n",
       "      <td>4850</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518073</td>\n",
       "      <td>0.326926</td>\n",
       "      <td>0.155001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.360970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.015005</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>839 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     author essay  sequence_abs predicted  probability_B1  probability_B2   \n",
       "0    A_3375  4355             0         1        0.506112        0.349380  \\\n",
       "1    A_3375  3375             1         2        0.325794        0.511743   \n",
       "2    A_3375  4466             2         2        0.347513        0.491908   \n",
       "3    A_3375  5217             3         1        0.494528        0.348384   \n",
       "4    A_3375  5310             4         2        0.182036        0.484657   \n",
       "..      ...   ...           ...       ...             ...             ...   \n",
       "834  A_4314  4613             7         3        0.029305        0.463089   \n",
       "835  A_4314  4314             8         1        0.516822        0.327856   \n",
       "836  A_4131  4216             7         1        0.517918        0.327224   \n",
       "837  A_4131  4131             9         1        0.518043        0.327208   \n",
       "838  A_4131  4850             9         1        0.518073        0.326926   \n",
       "\n",
       "     probability_C1  probability_C2   \n",
       "0          0.144508             0.0  \\\n",
       "1          0.162462             0.0   \n",
       "2          0.160579             0.0   \n",
       "3          0.157088             0.0   \n",
       "4          0.333307             0.0   \n",
       "..              ...             ...   \n",
       "834        0.507606             0.0   \n",
       "835        0.155322             0.0   \n",
       "836        0.154858             0.0   \n",
       "837        0.154750             0.0   \n",
       "838        0.155001             0.0   \n",
       "\n",
       "     scalarFeatures_Depth of the Parse Trees_0   \n",
       "0                                          9.0  \\\n",
       "1                                         10.0   \n",
       "2                                          8.0   \n",
       "3                                         10.0   \n",
       "4                                          8.0   \n",
       "..                                         ...   \n",
       "834                                       11.0   \n",
       "835                                       15.0   \n",
       "836                                       13.0   \n",
       "837                                        5.0   \n",
       "838                                       11.0   \n",
       "\n",
       "     scalarFeatures_Lexical Diversity_0  ...   \n",
       "0                              0.402510  ...  \\\n",
       "1                              0.383010  ...   \n",
       "2                              0.376060  ...   \n",
       "3                              0.392630  ...   \n",
       "4                              0.403300  ...   \n",
       "..                                  ...  ...   \n",
       "834                            0.417210  ...   \n",
       "835                            0.436890  ...   \n",
       "836                            0.385330  ...   \n",
       "837                            0.378947  ...   \n",
       "838                            0.360970  ...   \n",
       "\n",
       "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Astrattezza_0   \n",
       "0                                             0.025316                             \\\n",
       "1                                             0.116279                              \n",
       "2                                             0.181818                              \n",
       "3                                             0.097561                              \n",
       "4                                             0.149254                              \n",
       "..                                                 ...                              \n",
       "834                                           0.072917                              \n",
       "835                                           0.069364                              \n",
       "836                                           0.050000                              \n",
       "837                                           0.000000                              \n",
       "838                                           0.000000                              \n",
       "\n",
       "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Semiastrattezza_0   \n",
       "0                                             0.316456                                 \\\n",
       "1                                             0.372093                                  \n",
       "2                                             0.127273                                  \n",
       "3                                             0.365854                                  \n",
       "4                                             0.447761                                  \n",
       "..                                                 ...                                  \n",
       "834                                           0.375000                                  \n",
       "835                                           0.213873                                  \n",
       "836                                           0.150000                                  \n",
       "837                                           0.666667                                  \n",
       "838                                           0.166667                                  \n",
       "\n",
       "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Concretezza_0   \n",
       "0                                             0.658228                             \\\n",
       "1                                             0.511628                              \n",
       "2                                             0.690909                              \n",
       "3                                             0.536585                              \n",
       "4                                             0.402985                              \n",
       "..                                                 ...                              \n",
       "834                                           0.552083                              \n",
       "835                                           0.716763                              \n",
       "836                                           0.800000                              \n",
       "837                                           0.333333                              \n",
       "838                                           0.833333                              \n",
       "\n",
       "     simpleDistrFeatures_Sofisticatezza lessicale_parole vuote_0   \n",
       "0                                             0.013592            \\\n",
       "1                                             0.009919             \n",
       "2                                             0.013394             \n",
       "3                                             0.010912             \n",
       "4                                             0.012638             \n",
       "..                                                 ...             \n",
       "834                                           0.011855             \n",
       "835                                           0.014033             \n",
       "836                                           0.014866             \n",
       "837                                           0.009725             \n",
       "838                                           0.012090             \n",
       "\n",
       "     simpleDistrFeatures_Sofisticatezza lessicale_lemmi vuoti_0   \n",
       "0                                             0.015009           \\\n",
       "1                                             0.010709            \n",
       "2                                             0.011012            \n",
       "3                                             0.011711            \n",
       "4                                             0.010282            \n",
       "..                                                 ...            \n",
       "834                                           0.009249            \n",
       "835                                           0.008797            \n",
       "836                                           0.013510            \n",
       "837                                           0.015770            \n",
       "838                                           0.015005            \n",
       "\n",
       "     simpleDistrFeatures_Sofisticatezza lessicale_parole contenuto_0   \n",
       "0                                             0.000429                \\\n",
       "1                                             0.000845                 \n",
       "2                                             0.000554                 \n",
       "3                                             0.000835                 \n",
       "4                                             0.000472                 \n",
       "..                                                 ...                 \n",
       "834                                           0.000600                 \n",
       "835                                           0.000571                 \n",
       "836                                           0.000454                 \n",
       "837                                           0.000228                 \n",
       "838                                           0.000837                 \n",
       "\n",
       "     simpleDistrFeatures_Sofisticatezza lessicale_lemmi contenuto_0   \n",
       "0                                             0.000413               \\\n",
       "1                                             0.000645                \n",
       "2                                             0.000700                \n",
       "3                                             0.000794                \n",
       "4                                             0.000573                \n",
       "..                                                 ...                \n",
       "834                                           0.000498                \n",
       "835                                           0.000346                \n",
       "836                                           0.000552                \n",
       "837                                           0.000608                \n",
       "838                                           0.000665                \n",
       "\n",
       "     simpleDistrFeatures_Tasso di vocabolario di base_Fondamentali_0   \n",
       "0                                             0.854962                \\\n",
       "1                                             0.919118                 \n",
       "2                                             0.846774                 \n",
       "3                                             0.940678                 \n",
       "4                                             0.896104                 \n",
       "..                                                 ...                 \n",
       "834                                           0.923077                 \n",
       "835                                           0.817460                 \n",
       "836                                           0.880435                 \n",
       "837                                           0.977778                 \n",
       "838                                           0.944444                 \n",
       "\n",
       "     simpleDistrFeatures_Tasso di vocabolario di base_Alto uso_0   \n",
       "0                                             0.114504            \\\n",
       "1                                             0.066176             \n",
       "2                                             0.096774             \n",
       "3                                             0.050847             \n",
       "4                                             0.090909             \n",
       "..                                                 ...             \n",
       "834                                           0.060440             \n",
       "835                                           0.150794             \n",
       "836                                           0.076087             \n",
       "837                                           0.000000             \n",
       "838                                           0.041667             \n",
       "\n",
       "     simpleDistrFeatures_Tasso di vocabolario di base_Alto disponibilità_0  \n",
       "0                                             0.030534                      \n",
       "1                                             0.014706                      \n",
       "2                                             0.056452                      \n",
       "3                                             0.008475                      \n",
       "4                                             0.012987                      \n",
       "..                                                 ...                      \n",
       "834                                           0.016484                      \n",
       "835                                           0.031746                      \n",
       "836                                           0.043478                      \n",
       "837                                           0.022222                      \n",
       "838                                           0.013889                      \n",
       "\n",
       "[839 rows x 159 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.merge(df, df_malt, how='outer', on='essay')\n",
    "df_full['author'] = df_full[\"author\"].astype('category')\n",
    "#df_full['essay'] = df_full[\"essay\"].astype('category')\n",
    "\n",
    "y = df_full['sequence_abs'].copy()\n",
    "#y = y.astype(pd.CategoricalDtype(ordered=True))\n",
    "#y = y.astype(int)\n",
    "X = df_full.drop(columns='sequence_abs').copy()\n",
    "\n",
    "#df_full\n",
    "\n",
    "print(df_full[df_full.isna().any(axis=1)])\n",
    "print(df_full[df_full.isnull().any(axis=1)])\n",
    "\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns are: ['author']\n",
      "Ordinal columns are: ['predicted']\n",
      "Numerical columns are: ['probability_B1', 'probability_B2', 'probability_C1', 'probability_C2', 'scalarFeatures_Depth of the Parse Trees_0', 'scalarFeatures_Lexical Diversity_0', 'scalarFeatures_Maximal Non-Verbal Phrase - Mean_0', 'scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0', 'scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0', 'scalarFeatures_Non-Verbal Chains Length - Mean_0', 'scalarFeatures_Non-Verbal Chains Length - Std.Dev._0', 'scalarFeatures_Referential Cohesion - Mean_0', 'scalarFeatures_Referential Cohesion - Std.Dev._0', 'scalarFeatures_Sentence Length (in Tokens) - Mean_0', 'scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0', 'scalarFeatures_Subordinate Ratio - Mean_0', 'scalarFeatures_Subordinate Ratio - Std.Dev._0', 'scalarFeatures_Text Length (in Lemmas)_0', 'scalarFeatures_Text Length (in Sentences)_0', 'scalarFeatures_Token Length - Mean_0', 'scalarFeatures_Token Length - Std.Dev._0', 'scalarFeatures_Verbal Roots_0', 'simpleScalarFeatures_Lunghezza del testo_0', 'simpleScalarFeatures_Lunghezza media delle frasi_0', 'simpleScalarFeatures_Varietà lessicale_0', 'distrFeatures_Arity of Verbal Predicates_ 0 _0', 'distrFeatures_Arity of Verbal Predicates_ 1 _0', 'distrFeatures_Arity of Verbal Predicates_ 2 _0', 'distrFeatures_Arity of Verbal Predicates_ 3 _0', 'distrFeatures_Arity of Verbal Predicates_ 4 _0', 'distrFeatures_Arity of Verbal Predicates_Std.Dev._0', 'distrFeatures_Arity of Verbal Predicates_≥ 5_0', 'distrFeatures_Basic Vucabulary Rate_Fundamentals_0', 'distrFeatures_Basic Vucabulary Rate_High Availability_0', 'distrFeatures_Basic Vucabulary Rate_High Usage_0', 'distrFeatures_Deep Causal Cohesion_Entropy_0', 'distrFeatures_Deep Causal Cohesion_additive_0', 'distrFeatures_Deep Causal Cohesion_adversative_0', 'distrFeatures_Deep Causal Cohesion_alternative_0', 'distrFeatures_Deep Causal Cohesion_causal_0', 'distrFeatures_Deep Causal Cohesion_marking results_0', 'distrFeatures_Deep Causal Cohesion_reformulation_0', 'distrFeatures_Deep Causal Cohesion_temporal_0', 'distrFeatures_Deep Causal Cohesion_transitions_0', 'distrFeatures_Dependency Links Length_Max_0', 'distrFeatures_Dependency Links Length_Mean_0', 'distrFeatures_Dependency Links Length_Std.Dev._0', 'distrFeatures_Dependency Tags Distribution_Entropy_0', 'distrFeatures_Dependency Tags Distribution_acl_0', 'distrFeatures_Dependency Tags Distribution_advcl_0', 'distrFeatures_Dependency Tags Distribution_advmod_0', 'distrFeatures_Dependency Tags Distribution_amod_0', 'distrFeatures_Dependency Tags Distribution_appos_0', 'distrFeatures_Dependency Tags Distribution_aux_0', 'distrFeatures_Dependency Tags Distribution_case_0', 'distrFeatures_Dependency Tags Distribution_cc_0', 'distrFeatures_Dependency Tags Distribution_ccomp_0', 'distrFeatures_Dependency Tags Distribution_compound_0', 'distrFeatures_Dependency Tags Distribution_conj_0', 'distrFeatures_Dependency Tags Distribution_cop_0', 'distrFeatures_Dependency Tags Distribution_csubj_0', 'distrFeatures_Dependency Tags Distribution_det_0', 'distrFeatures_Dependency Tags Distribution_discourse_0', 'distrFeatures_Dependency Tags Distribution_dislocated_0', 'distrFeatures_Dependency Tags Distribution_expl_0', 'distrFeatures_Dependency Tags Distribution_fixed_0', 'distrFeatures_Dependency Tags Distribution_flat_0', 'distrFeatures_Dependency Tags Distribution_iobj_0', 'distrFeatures_Dependency Tags Distribution_mark_0', 'distrFeatures_Dependency Tags Distribution_nmod_0', 'distrFeatures_Dependency Tags Distribution_nsubj_0', 'distrFeatures_Dependency Tags Distribution_nummod_0', 'distrFeatures_Dependency Tags Distribution_obj_0', 'distrFeatures_Dependency Tags Distribution_obl_0', 'distrFeatures_Dependency Tags Distribution_parataxis_0', 'distrFeatures_Dependency Tags Distribution_punct_0', 'distrFeatures_Dependency Tags Distribution_root_0', 'distrFeatures_Dependency Tags Distribution_vocative_0', 'distrFeatures_Dependency Tags Distribution_xcomp_0', 'distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0', 'distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0', 'distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0', 'distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0', 'distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0', 'distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0', 'distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0', 'distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0', 'distrFeatures_Lexical Variation Feature_Adj A_0', 'distrFeatures_Lexical Variation Feature_Adj B_0', 'distrFeatures_Lexical Variation Feature_Adv A_0', 'distrFeatures_Lexical Variation Feature_Adv B_0', 'distrFeatures_Lexical Variation Feature_Noun A_0', 'distrFeatures_Lexical Variation Feature_Noun B_0', 'distrFeatures_Lexical Variation Feature_Verb A_0', 'distrFeatures_Lexical Variation Feature_Verb B_0', 'distrFeatures_MCI (Morphological Complexity Index)_Nouns_0', 'distrFeatures_MCI (Morphological Complexity Index)_Verbs_0', 'distrFeatures_Nouns Abstractness Distribution_Abstract_0', 'distrFeatures_Nouns Abstractness Distribution_Concrete_0', 'distrFeatures_Nouns Abstractness Distribution_Semiabstract_0', 'distrFeatures_Number of Syntactic Constituents_Clauses_0', 'distrFeatures_Number of Syntactic Constituents_Coordinate Phrases_0', 'distrFeatures_Number of Syntactic Constituents_Mean NP per sentence_0', 'distrFeatures_Number of Syntactic Constituents_Subordinate Clauses_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_ADJ_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_ADP_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_ADV_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_AUX_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_CCONJ_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_DET_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_Entropy_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_INTJ_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_NOUN_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_NUM_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_PART_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_PRON_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_PROPN_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_PUNCT_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_SCONJ_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_SYM_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_VERB_0', 'distrFeatures_POS (Part-of-speech) Tags Distribution_X_0', 'distrFeatures_Relative Subordinate Order_ 1 _0', 'distrFeatures_Relative Subordinate Order_ 2 _0', 'distrFeatures_Relative Subordinate Order_ 3 _0', 'distrFeatures_Relative Subordinate Order_ 4 _0', 'distrFeatures_Relative Subordinate Order_Mean_0', 'distrFeatures_Relative Subordinate Order_Std.Dev._0', 'distrFeatures_Relative Subordinate Order_≥ 5_0', 'distrFeatures_Subordination Chains Length_ 1 _0', 'distrFeatures_Subordination Chains Length_ 2 _0', 'distrFeatures_Subordination Chains Length_Mean_0', 'distrFeatures_Subordination Chains Length_Std.Dev._0', 'distrFeatures_Subordination Chains Length_≥ 3_0', 'distrFeatures_Syntatic Complexity Feature_Mean Coordinate Phrases per Clause_0', 'distrFeatures_Syntatic Complexity Feature_Sentence Complexity Ratio_0', 'distrFeatures_Syntatic Complexity Feature_Sentence Coordination Ratio_0', 'distrFeatures_Verbal Mood Distribution_ Inf _0', 'distrFeatures_Verbal Mood Distribution_Cnd_0', 'distrFeatures_Verbal Mood Distribution_Entropy_0', 'distrFeatures_Verbal Mood Distribution_Ger_0', 'distrFeatures_Verbal Mood Distribution_Imp_0', 'distrFeatures_Verbal Mood Distribution_Ind_0', 'distrFeatures_Verbal Mood Distribution_Part_0', 'distrFeatures_Verbal Mood Distribution_Sub_0', \"simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Astrattezza_0\", \"simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Semiastrattezza_0\", \"simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Concretezza_0\", 'simpleDistrFeatures_Sofisticatezza lessicale_parole vuote_0', 'simpleDistrFeatures_Sofisticatezza lessicale_lemmi vuoti_0', 'simpleDistrFeatures_Sofisticatezza lessicale_parole contenuto_0', 'simpleDistrFeatures_Sofisticatezza lessicale_lemmi contenuto_0', 'simpleDistrFeatures_Tasso di vocabolario di base_Fondamentali_0', 'simpleDistrFeatures_Tasso di vocabolario di base_Alto uso_0', 'simpleDistrFeatures_Tasso di vocabolario di base_Alto disponibilità_0']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, GroupKFold\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from langlearn.dataprep.pipes import sklearn_pipe\n",
    "from langlearn.dataprep.transformers import GroupNormalizer\n",
    "\n",
    "#df_full_scaled = gn.transform(df_full.iloc[0:100, :])\n",
    "#df_full_scaled = gn.transform(df_full)\n",
    "\n",
    "pipe = sklearn_pipe(X, verbose=True)\n",
    "spacy_fu = FeatureUnion(transformer_list=[\n",
    "        ('spacy_wf', spacy_wf),\n",
    "        #('spacy_lem', spacy_wf),\n",
    "        ('spacy_pos', spacy_pos),\n",
    "        ('spacy_dep', spacy_dep),\n",
    "        ('spacy_morph', spacy_morph),\n",
    "    ], verbose=True)\n",
    "\n",
    "spacy_pipe = ColumnTransformer([\n",
    "        ('spacy_pipe', spacy_fu, 'essay'),\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    n_jobs=1, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "gn_pipe = Pipeline([\n",
    "    ('fu', FeatureUnion([\n",
    "        ('ct_passthrough_author', ColumnTransformer([\n",
    "            ('passthrough', 'passthrough', ['author'])\n",
    "            ], remainder='drop', verbose=True)\n",
    "        ),\n",
    "        ('ct_passthrough_numbers', ColumnTransformer([\n",
    "                ('passthrough', 'passthrough', make_column_selector(dtype_include='number')),\n",
    "            ], remainder='drop', verbose=True)\n",
    "        ),\n",
    "        ], verbose=True)\n",
    "    ),\n",
    "    ('gn', GroupNormalizer())\n",
    "], verbose=True).set_output(transform='pandas')\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    (\"pipe\", pipe),\n",
    "    ('gn', gn_pipe),\n",
    "    ('spacy', spacy_pipe),\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "scoring = ['neg_mean_absolute_error', 'explained_variance', 'r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from langlearn.dataprep.transformers import GroupNormalizer\n",
    "\n",
    "stdscaler = StandardScaler() # with_mean=False)\n",
    "\n",
    "#pca = PCA(100)\n",
    "pca = TruncatedSVD(n_components=125)\n",
    "\n",
    "dtregressor = DecisionTreeRegressor(random_state=42)\n",
    "hgbreg = HistGradientBoostingRegressor(loss='squared_error')\n",
    "svmreg = svm.SVR(kernel=\"rbf\", C=1e1, gamma=0.1) #, C=100, gamma=\"auto\", degree=3, epsilon=0.1, coef0=1)\n",
    "krreg = KernelRidge(kernel='rbf')\n",
    "\n",
    "\n",
    "estimators = [svmreg, hgbreg, krreg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "      ..\n",
       "834    7\n",
       "835    8\n",
       "836    7\n",
       "837    9\n",
       "838    9\n",
       "Name: sequence_abs, Length: 839, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_in = X.iloc[0:15, :]\n",
    "#y_in = y[0:15]\n",
    "#\n",
    "X_in = X.copy()\n",
    "y_in = y.copy()\n",
    "\n",
    "proc_pipe = Pipeline(steps=[\n",
    "    ('combined_features', combined_features),\n",
    "    ('to_dense', FunctionTransformer(lambda x: np.asarray(x.todense()), accept_sparse=True)),\n",
    "    ('scaler_std', stdscaler),\n",
    "    ('redux_pca', pca),\n",
    "    ('estimator_svmreg', estimators[1])\n",
    "], verbose=True)\n",
    "\n",
    "y_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 3) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 3) Processing ord, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing imputer, total=   0.0s\n",
      "[ColumnTransformer] ........... (3 of 3) Processing num, total=   0.0s\n",
      "[FeatureUnion] .......... (step 1 of 1) Processing pipe, total=   0.0s\n",
      "[Pipeline] . (step 1 of 2) Processing combined_features, total=   0.0s\n",
      "[Pipeline] .. (step 2 of 2) Processing estimator_svmreg, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 3) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 3) Processing ord, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing imputer, total=   0.0s\n",
      "[ColumnTransformer] ........... (3 of 3) Processing num, total=   0.0s\n",
      "[FeatureUnion] .......... (step 1 of 1) Processing pipe, total=   0.0s\n",
      "[Pipeline] . (step 1 of 2) Processing combined_features, total=   0.0s\n",
      "[Pipeline] .. (step 2 of 2) Processing estimator_svmreg, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 3) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 3) Processing ord, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing imputer, total=   0.0s\n",
      "[ColumnTransformer] ........... (3 of 3) Processing num, total=   0.0s\n",
      "[FeatureUnion] .......... (step 1 of 1) Processing pipe, total=   0.0s\n",
      "[Pipeline] . (step 1 of 2) Processing combined_features, total=   0.0s\n",
      "[Pipeline] .. (step 2 of 2) Processing estimator_svmreg, total=   0.0s\n",
      "{'fit_time': array([0.04474759, 0.04281282, 0.04271221]), 'score_time': array([0.01578093, 0.01597071, 0.01600266]), 'test_neg_mean_absolute_error': array([-2.74653351, -2.75020436, -2.83756314]), 'test_explained_variance': array([-0.08660243,  0.05202859,  0.0650304 ]), 'test_r2': array([-0.08662046, -0.02662006,  0.0443454 ])}\n",
      "fit_time: 0.04342420895894369 0.0009366734695608051\n",
      "score_time: 0.01591809590657552 9.786694657469466e-05\n",
      "test_neg_mean_absolute_error: -2.7781003358607044 0.04207324901829133\n",
      "test_explained_variance: 0.010152185988283787 0.0686214425075508\n",
      "test_r2: -0.02296503938202436 0.0535290160260324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "scores = cross_validate(proc_pipe, X_in, y_in, cv=KFold(n_splits=3, shuffle=True, random_state=24), scoring=scoring, n_jobs=1, verbose=True, error_score='raise')\n",
    "print(scores)\n",
    "for score in scores:\n",
    "    print(f\"{score}: {scores[score].mean()} {scores[score].std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingRegressor() for preproc_pipe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 3) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 3) Processing ord, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 2) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing scaler, total=   0.0s\n",
      "[ColumnTransformer] ........... (3 of 3) Processing num, total=   0.0s\n",
      "[FeatureUnion] .......... (step 1 of 3) Processing pipe, total=   0.0s\n",
      "[ColumnTransformer] ... (1 of 1) Processing passthrough, total=   0.0s\n",
      "[FeatureUnion]  (step 1 of 2) Processing ct_passthrough_author, total=   0.0s\n",
      "[ColumnTransformer] ... (1 of 1) Processing passthrough, total=   0.0s\n",
      "[FeatureUnion]  (step 2 of 2) Processing ct_passthrough_numbers, total=   0.0s\n",
      "[Pipeline] ................ (step 1 of 2) Processing fu, total=   0.0s\n",
      "GN.fit: (559, 156)\n",
      "ct_passthrough_author__passthrough__author\n",
      "GN.transform: (559, 156)\n",
      "...GN.transformed: (559, 155)\n",
      "[Pipeline] ................ (step 2 of 2) Processing gn, total=   0.6s\n",
      "[FeatureUnion] ............ (step 2 of 3) Processing gn, total=   0.6s\n",
      "[Pipeline] .......... (step 1 of 2) Processing wordform, total=   0.1s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.4s\n",
      "[FeatureUnion] ...... (step 1 of 4) Processing spacy_wf, total=   0.5s\n",
      "[Pipeline] ............... (step 1 of 2) Processing pos, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.1s\n",
      "[FeatureUnion] ..... (step 2 of 4) Processing spacy_pos, total=   0.2s\n",
      "[Pipeline] ............... (step 1 of 2) Processing dep, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.1s\n",
      "[FeatureUnion] ..... (step 3 of 4) Processing spacy_dep, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing morph, total=  33.2s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.4s\n",
      "[FeatureUnion] ... (step 4 of 4) Processing spacy_morph, total=  33.6s\n",
      "[ColumnTransformer] .... (1 of 1) Processing spacy_pipe, total=  34.4s\n",
      "[FeatureUnion] ......... (step 3 of 3) Processing spacy, total= 1.5min\n",
      "[Pipeline] . (step 1 of 5) Processing combined_features, total= 1.5min\n",
      "[Pipeline] .......... (step 2 of 5) Processing to_dense, total=   0.0s\n",
      "[Pipeline] ........ (step 3 of 5) Processing scaler_std, total=   0.1s\n",
      "[Pipeline] ......... (step 4 of 5) Processing redux_pca, total=   0.8s\n",
      "[Pipeline] .. (step 5 of 5) Processing estimator_svmreg, total=   0.4s\n",
      "GN.transform: (280, 156)\n",
      "...GN.transformed: (280, 155)\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 3) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 3) Processing ord, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 2) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing scaler, total=   0.0s\n",
      "[ColumnTransformer] ........... (3 of 3) Processing num, total=   0.0s\n",
      "[FeatureUnion] .......... (step 1 of 3) Processing pipe, total=   0.0s\n",
      "[ColumnTransformer] ... (1 of 1) Processing passthrough, total=   0.0s\n",
      "[FeatureUnion]  (step 1 of 2) Processing ct_passthrough_author, total=   0.0s\n",
      "[ColumnTransformer] ... (1 of 1) Processing passthrough, total=   0.0s\n",
      "[FeatureUnion]  (step 2 of 2) Processing ct_passthrough_numbers, total=   0.0s\n",
      "[Pipeline] ................ (step 1 of 2) Processing fu, total=   0.0s\n",
      "GN.fit: (559, 156)\n",
      "ct_passthrough_author__passthrough__author\n",
      "GN.transform: (559, 156)\n",
      "...GN.transformed: (559, 155)\n",
      "[Pipeline] ................ (step 2 of 2) Processing gn, total=   1.3s\n",
      "[FeatureUnion] ............ (step 2 of 3) Processing gn, total=   1.3s\n",
      "[Pipeline] .......... (step 1 of 2) Processing wordform, total=   0.1s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   1.2s\n",
      "[FeatureUnion] ...... (step 1 of 4) Processing spacy_wf, total=   1.3s\n",
      "[Pipeline] ............... (step 1 of 2) Processing pos, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.2s\n",
      "[FeatureUnion] ..... (step 2 of 4) Processing spacy_pos, total=   0.2s\n",
      "[Pipeline] ............... (step 1 of 2) Processing dep, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.3s\n",
      "[FeatureUnion] ..... (step 3 of 4) Processing spacy_dep, total=   0.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing morph, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.7s\n",
      "[FeatureUnion] ... (step 4 of 4) Processing spacy_morph, total=   1.0s\n",
      "[ColumnTransformer] .... (1 of 1) Processing spacy_pipe, total=   2.9s\n",
      "[FeatureUnion] ......... (step 3 of 3) Processing spacy, total= 1.2min\n",
      "[Pipeline] . (step 1 of 5) Processing combined_features, total= 1.2min\n",
      "[Pipeline] .......... (step 2 of 5) Processing to_dense, total=   0.1s\n",
      "[Pipeline] ........ (step 3 of 5) Processing scaler_std, total=   0.2s\n",
      "[Pipeline] ......... (step 4 of 5) Processing redux_pca, total=   1.2s\n",
      "[Pipeline] .. (step 5 of 5) Processing estimator_svmreg, total=   0.4s\n",
      "GN.transform: (280, 156)\n",
      "...GN.transformed: (280, 155)\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 3) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 3) Processing ord, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 2) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing scaler, total=   0.0s\n",
      "[ColumnTransformer] ........... (3 of 3) Processing num, total=   0.0s\n",
      "[FeatureUnion] .......... (step 1 of 3) Processing pipe, total=   0.0s\n",
      "[ColumnTransformer] ... (1 of 1) Processing passthrough, total=   0.0s\n",
      "[FeatureUnion]  (step 1 of 2) Processing ct_passthrough_author, total=   0.0s\n",
      "[ColumnTransformer] ... (1 of 1) Processing passthrough, total=   0.0s\n",
      "[FeatureUnion]  (step 2 of 2) Processing ct_passthrough_numbers, total=   0.0s\n",
      "[Pipeline] ................ (step 1 of 2) Processing fu, total=   0.0s\n",
      "GN.fit: (560, 156)\n",
      "ct_passthrough_author__passthrough__author\n",
      "GN.transform: (560, 156)\n",
      "...GN.transformed: (560, 155)\n",
      "[Pipeline] ................ (step 2 of 2) Processing gn, total=   0.8s\n",
      "[FeatureUnion] ............ (step 2 of 3) Processing gn, total=   0.8s\n",
      "[Pipeline] .......... (step 1 of 2) Processing wordform, total=   0.1s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.4s\n",
      "[FeatureUnion] ...... (step 1 of 4) Processing spacy_wf, total=   0.5s\n",
      "[Pipeline] ............... (step 1 of 2) Processing pos, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.1s\n",
      "[FeatureUnion] ..... (step 2 of 4) Processing spacy_pos, total=   0.2s\n",
      "[Pipeline] ............... (step 1 of 2) Processing dep, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.1s\n",
      "[FeatureUnion] ..... (step 3 of 4) Processing spacy_dep, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing morph, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.3s\n",
      "[FeatureUnion] ... (step 4 of 4) Processing spacy_morph, total=   0.7s\n",
      "[ColumnTransformer] .... (1 of 1) Processing spacy_pipe, total=   1.4s\n",
      "[FeatureUnion] ......... (step 3 of 3) Processing spacy, total=  25.8s\n",
      "[Pipeline] . (step 1 of 5) Processing combined_features, total=  26.6s\n",
      "[Pipeline] .......... (step 2 of 5) Processing to_dense, total=   0.0s\n",
      "[Pipeline] ........ (step 3 of 5) Processing scaler_std, total=   0.1s\n",
      "[Pipeline] ......... (step 4 of 5) Processing redux_pca, total=   0.9s\n",
      "[Pipeline] .. (step 5 of 5) Processing estimator_svmreg, total=   0.6s\n",
      "GN.transform: (279, 156)\n",
      "...GN.transformed: (279, 155)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([92.35137105, 73.35504913, 28.14166784]), 'score_time': array([1.41998029, 1.81187057, 0.9666121 ]), 'test_neg_mean_absolute_error': array([-2.21135849, -2.36806676, -2.37939709]), 'test_explained_variance': array([0.34489916, 0.24752218, 0.15673057]), 'test_r2': array([0.33991347, 0.24109432, 0.15638299])}\n",
      "test_neg_mean_absolute_error: -2.3196  0.0767\n",
      "test_explained_variance     :  0.2497  0.0768\n",
      "test_r2                     :  0.2458  0.0750\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/joblib/parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[1;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/queue.py:167\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> 167\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    168\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[202], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m:\u001b[39;00m\u001b[39m <\u001b[39m\u001b[39m{\u001b[39;00mscore_maxlength\u001b[39m}\u001b[39;00m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mscores[score]\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m .4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mscores[score]\u001b[39m.\u001b[39mstd()\u001b[39m:\u001b[39;00m\u001b[39m .4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39m#y_preds = list()\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m#for trained_esimator in scores['estimator']:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m#    y_preds.extend(cross_val_predict(trained_esimator, X, y, groups=X['author'], cv=GroupKFold(n_splits=10), n_jobs=-1))\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m y_pred \u001b[39m=\u001b[39m cross_val_predict(processor, _X\u001b[39m.\u001b[39;49mcopy(), _y\u001b[39m.\u001b[39;49mcopy(), groups\u001b[39m=\u001b[39;49m_X[\u001b[39m'\u001b[39;49m\u001b[39mauthor\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m     25\u001b[0m                            cv\u001b[39m=\u001b[39;49mGroupKFold(n_splits\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m), n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     26\u001b[0m \u001b[39m#print(y_pred)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m# print(np.array(y_preds).round(0).astype(int))\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mconfusion_matrix(_y, y_pred\u001b[39m.\u001b[39mround(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)))\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:986\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    985\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 986\u001b[0m predictions \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    987\u001b[0m     delayed(_fit_and_predict)(\n\u001b[1;32m    988\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m splits\n\u001b[1;32m    991\u001b[0m )\n\u001b[1;32m    993\u001b[0m inv_test_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mlen\u001b[39m(test_indices), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m    994\u001b[0m inv_test_indices[test_indices] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(test_indices))\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/joblib/parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[1;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[0;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[1;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/utils/parallel.py:59\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m---> 59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:988\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    985\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m    986\u001b[0m predictions \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    987\u001b[0m     delayed(_fit_and_predict)(\n\u001b[0;32m--> 988\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m splits\n\u001b[1;32m    991\u001b[0m )\n\u001b[1;32m    993\u001b[0m inv_test_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mlen\u001b[39m(test_indices), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m    994\u001b[0m inv_test_indices[test_indices] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(test_indices))\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:89\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     87\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m new_object_params\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> 89\u001b[0m     new_object_params[name] \u001b[39m=\u001b[39m clone(param, safe\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     90\u001b[0m new_object \u001b[39m=\u001b[39m klass(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_object_params)\n\u001b[1;32m     91\u001b[0m params_set \u001b[39m=\u001b[39m new_object\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:67\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# XXX: not handling dictionaries\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m estimator_type \u001b[39min\u001b[39;00m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mset\u001b[39m, \u001b[39mfrozenset\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator_type([clone(e, safe\u001b[39m=\u001b[39msafe) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m estimator])\n\u001b[1;32m     68\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m safe:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:67\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# XXX: not handling dictionaries\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m estimator_type \u001b[39min\u001b[39;00m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mset\u001b[39m, \u001b[39mfrozenset\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator_type([clone(e, safe\u001b[39m=\u001b[39;49msafe) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m estimator])\n\u001b[1;32m     68\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m safe:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:67\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# XXX: not handling dictionaries\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m estimator_type \u001b[39min\u001b[39;00m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mset\u001b[39m, \u001b[39mfrozenset\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator_type([clone(e, safe\u001b[39m=\u001b[39msafe) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m estimator])\n\u001b[1;32m     68\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m safe:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:67\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# XXX: not handling dictionaries\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m estimator_type \u001b[39min\u001b[39;00m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mset\u001b[39m, \u001b[39mfrozenset\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator_type([clone(e, safe\u001b[39m=\u001b[39;49msafe) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m estimator])\n\u001b[1;32m     68\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m safe:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:89\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     87\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m new_object_params\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> 89\u001b[0m     new_object_params[name] \u001b[39m=\u001b[39m clone(param, safe\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     90\u001b[0m new_object \u001b[39m=\u001b[39m klass(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_object_params)\n\u001b[1;32m     91\u001b[0m params_set \u001b[39m=\u001b[39m new_object\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "    \u001b[0;31m[... skipping similar frames: <listcomp> at line 67 (7 times), clone at line 67 (7 times), clone at line 89 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:67\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# XXX: not handling dictionaries\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m estimator_type \u001b[39min\u001b[39;00m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mset\u001b[39m, \u001b[39mfrozenset\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator_type([clone(e, safe\u001b[39m=\u001b[39msafe) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m estimator])\n\u001b[1;32m     68\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m safe:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:67\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m# XXX: not handling dictionaries\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m estimator_type \u001b[39min\u001b[39;00m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mset\u001b[39m, \u001b[39mfrozenset\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator_type([clone(e, safe\u001b[39m=\u001b[39;49msafe) \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m estimator])\n\u001b[1;32m     68\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m safe:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:89\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     87\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m new_object_params\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> 89\u001b[0m     new_object_params[name] \u001b[39m=\u001b[39m clone(param, safe\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     90\u001b[0m new_object \u001b[39m=\u001b[39m klass(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_object_params)\n\u001b[1;32m     91\u001b[0m params_set \u001b[39m=\u001b[39m new_object\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/sklearn/base.py:70\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m safe:\n\u001b[0;32m---> 70\u001b[0m         \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39;49mdeepcopy(estimator)\n\u001b[1;32m     71\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(estimator, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/copy.py:264\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m deep \u001b[39mand\u001b[39;00m args:\n\u001b[1;32m    263\u001b[0m     args \u001b[39m=\u001b[39m (deepcopy(arg, memo) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)\n\u001b[0;32m--> 264\u001b[0m y \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m    266\u001b[0m     memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/copy.py:263\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m deep \u001b[39m=\u001b[39m memo \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m deep \u001b[39mand\u001b[39;00m args:\n\u001b[0;32m--> 263\u001b[0m     args \u001b[39m=\u001b[39m (deepcopy(arg, memo) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)\n\u001b[1;32m    264\u001b[0m y \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m deep:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/copy.py:264\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m deep \u001b[39mand\u001b[39;00m args:\n\u001b[1;32m    263\u001b[0m     args \u001b[39m=\u001b[39m (deepcopy(arg, memo) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)\n\u001b[0;32m--> 264\u001b[0m y \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m    266\u001b[0m     memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/spacy/vocab.pyx:577\u001b[0m, in \u001b[0;36mspacy.vocab.unpickle_vocab\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/usr/local/ubuntu-x86_64/opt/miniconda3/envs/evalita/lib/python3.8/site-packages/srsly/_pickle_api.py:17\u001b[0m, in \u001b[0;36mpickle_loads\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Serialize a Python object with pickle.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[39m    data: The object to serialize.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m    protocol (int): Protocol to use. -1 for highest.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m    RETURNS (bytes): The serialized object.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m cloudpickle\u001b[39m.\u001b[39mdumps(data, protocol\u001b[39m=\u001b[39mprotocol)\n\u001b[0;32m---> 17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpickle_loads\u001b[39m(data: \u001b[39mbytes\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m JSONOutput:\n\u001b[1;32m     18\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Deserialize bytes with pickle.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m    data (bytes): The data to deserialize.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m    RETURNS: The deserialized Python object.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m cloudpickle\u001b[39m.\u001b[39mloads(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X_in = X.copy()\n",
    "y_in = y.copy()\n",
    "\n",
    "for estimator in estimators[1:2]:\n",
    "\n",
    "    for processor, preprocessor_name, _X, _y in [(proc_pipe, 'preproc_pipe', X_in, y_in)]:\n",
    "        print(f'{estimator} for {preprocessor_name}')\n",
    "        \n",
    "        # scores = cross_validate(make_pipeline(preprocessor, estimator), X, y, return_estimator=True, cv=10, scoring=scoring, n_jobs=-1)\n",
    "        scores = cross_validate(processor, _X.copy(), _y.copy(), return_estimator=False, groups=_X['author'], \n",
    "                                cv=GroupKFold(n_splits=3), scoring=scoring, n_jobs=1, error_score='raise', verbose=True)\n",
    "        print(scores)\n",
    "        score_maxlength = max([len(score) for score in scores if score.startswith('test_')])\n",
    "        for score in [score for score in scores if score.startswith('test_')]:\n",
    "            print(f\"{score: <{score_maxlength}}: {scores[score].mean(): .4f} {scores[score].std(): .4f}\")\n",
    "                \n",
    "        #y_preds = list()\n",
    "        #for trained_esimator in scores['estimator']:\n",
    "        #    y_preds.extend(cross_val_predict(trained_esimator, X, y, groups=X['author'], cv=GroupKFold(n_splits=10), n_jobs=-1))\n",
    "        y_pred = cross_val_predict(processor, _X.copy(), _y.copy(), groups=_X['author'], \n",
    "                                   cv=GroupKFold(n_splits=3), n_jobs=1, verbose=True)\n",
    "        #print(y_pred)\n",
    "        # print(np.array(y_preds).round(0).astype(int))\n",
    "        print(sklearn.metrics.confusion_matrix(_y, y_pred.round(0).astype(int)))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.metrics import PredictionErrorDisplay\n",
    "\n",
    "        fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "        PredictionErrorDisplay.from_predictions(\n",
    "            _y,\n",
    "            y_pred=y_pred,\n",
    "            kind=\"actual_vs_predicted\",\n",
    "            #subsample=250,\n",
    "            ax=axs[0],\n",
    "            random_state=0,\n",
    "        )\n",
    "        axs[0].set_title(\"Actual vs. Predicted values\")\n",
    "        \n",
    "        PredictionErrorDisplay.from_predictions(\n",
    "            _y,\n",
    "            y_pred=y_pred,\n",
    "            kind=\"residual_vs_predicted\",\n",
    "            #subsample=250,\n",
    "            ax=axs[1],\n",
    "            random_state=0,\n",
    "        )\n",
    "        axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
    "        \n",
    "        fig.suptitle(\"Plotting cross-validated predictions\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print('####\\n')\n",
    "        # https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_predict.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4708780135319408"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#local_pipe.score(X_in, y_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>essay</th>\n",
       "      <th>sequence_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>5388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>5222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>4853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>3116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>5192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>A_4019</td>\n",
       "      <td>4019</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>A_4152</td>\n",
       "      <td>5201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>A_4152</td>\n",
       "      <td>4152</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>A_3291</td>\n",
       "      <td>3291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>A_3291</td>\n",
       "      <td>5130</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     author essay  sequence_abs\n",
       "0    A_3116  5388             0\n",
       "1    A_3116  5222             0\n",
       "2    A_3116  4853             0\n",
       "3    A_3116  3116             0\n",
       "4    A_3116  5192             0\n",
       "..      ...   ...           ...\n",
       "455  A_4019  4019             7\n",
       "456  A_4152  5201             1\n",
       "457  A_4152  4152             7\n",
       "458  A_3291  3291             1\n",
       "459  A_3291  5130             4\n",
       "\n",
       "[460 rows x 3 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_cita_tsv = data_prefix+'/raw/LangLearn_Test_Data/CItA/Test_CItA.tsv'\n",
    "df_test,tsv_test = read_cita_tsv(testing_cita_tsv)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [essay, predicted, probability_B1, probability_B2, probability_C1, probability_C2, scalarFeatures_Depth of the Parse Trees_0, scalarFeatures_Lexical Diversity_0, scalarFeatures_Maximal Non-Verbal Phrase - Mean_0, scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0, scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0, scalarFeatures_Non-Verbal Chains Length - Mean_0, scalarFeatures_Non-Verbal Chains Length - Std.Dev._0, scalarFeatures_Referential Cohesion - Mean_0, scalarFeatures_Referential Cohesion - Std.Dev._0, scalarFeatures_Sentence Length (in Tokens) - Mean_0, scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0, scalarFeatures_Subordinate Ratio - Mean_0, scalarFeatures_Subordinate Ratio - Std.Dev._0, scalarFeatures_Text Length (in Lemmas)_0, scalarFeatures_Text Length (in Sentences)_0, scalarFeatures_Token Length - Mean_0, scalarFeatures_Token Length - Std.Dev._0, scalarFeatures_Verbal Roots_0, simpleScalarFeatures_Lunghezza del testo_0, simpleScalarFeatures_Lunghezza media delle frasi_0, simpleScalarFeatures_Varietà lessicale_0, distrFeatures_Arity of Verbal Predicates_ 0 _0, distrFeatures_Arity of Verbal Predicates_ 1 _0, distrFeatures_Arity of Verbal Predicates_ 2 _0, distrFeatures_Arity of Verbal Predicates_ 3 _0, distrFeatures_Arity of Verbal Predicates_ 4 _0, distrFeatures_Arity of Verbal Predicates_Std.Dev._0, distrFeatures_Arity of Verbal Predicates_≥ 5_0, distrFeatures_Basic Vucabulary Rate_Fundamentals_0, distrFeatures_Basic Vucabulary Rate_High Availability_0, distrFeatures_Basic Vucabulary Rate_High Usage_0, distrFeatures_Deep Causal Cohesion_Entropy_0, distrFeatures_Deep Causal Cohesion_additive_0, distrFeatures_Deep Causal Cohesion_adversative_0, distrFeatures_Deep Causal Cohesion_alternative_0, distrFeatures_Deep Causal Cohesion_causal_0, distrFeatures_Deep Causal Cohesion_marking results_0, distrFeatures_Deep Causal Cohesion_reformulation_0, distrFeatures_Deep Causal Cohesion_temporal_0, distrFeatures_Deep Causal Cohesion_transitions_0, distrFeatures_Dependency Links Length_Max_0, distrFeatures_Dependency Links Length_Mean_0, distrFeatures_Dependency Links Length_Std.Dev._0, distrFeatures_Dependency Tags Distribution_Entropy_0, distrFeatures_Dependency Tags Distribution_acl_0, distrFeatures_Dependency Tags Distribution_advcl_0, distrFeatures_Dependency Tags Distribution_advmod_0, distrFeatures_Dependency Tags Distribution_amod_0, distrFeatures_Dependency Tags Distribution_appos_0, distrFeatures_Dependency Tags Distribution_aux_0, distrFeatures_Dependency Tags Distribution_case_0, distrFeatures_Dependency Tags Distribution_cc_0, distrFeatures_Dependency Tags Distribution_ccomp_0, distrFeatures_Dependency Tags Distribution_compound_0, distrFeatures_Dependency Tags Distribution_conj_0, distrFeatures_Dependency Tags Distribution_cop_0, distrFeatures_Dependency Tags Distribution_csubj_0, distrFeatures_Dependency Tags Distribution_det_0, distrFeatures_Dependency Tags Distribution_discourse_0, distrFeatures_Dependency Tags Distribution_dislocated_0, distrFeatures_Dependency Tags Distribution_expl_0, distrFeatures_Dependency Tags Distribution_fixed_0, distrFeatures_Dependency Tags Distribution_flat_0, distrFeatures_Dependency Tags Distribution_iobj_0, distrFeatures_Dependency Tags Distribution_mark_0, distrFeatures_Dependency Tags Distribution_nmod_0, distrFeatures_Dependency Tags Distribution_nsubj_0, distrFeatures_Dependency Tags Distribution_nummod_0, distrFeatures_Dependency Tags Distribution_obj_0, distrFeatures_Dependency Tags Distribution_obl_0, distrFeatures_Dependency Tags Distribution_parataxis_0, distrFeatures_Dependency Tags Distribution_punct_0, distrFeatures_Dependency Tags Distribution_root_0, distrFeatures_Dependency Tags Distribution_vocative_0, distrFeatures_Dependency Tags Distribution_xcomp_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0, distrFeatures_Lexical Variation Feature_Adj A_0, distrFeatures_Lexical Variation Feature_Adj B_0, distrFeatures_Lexical Variation Feature_Adv A_0, distrFeatures_Lexical Variation Feature_Adv B_0, distrFeatures_Lexical Variation Feature_Noun A_0, distrFeatures_Lexical Variation Feature_Noun B_0, distrFeatures_Lexical Variation Feature_Verb A_0, distrFeatures_Lexical Variation Feature_Verb B_0, distrFeatures_MCI (Morphological Complexity Index)_Nouns_0, distrFeatures_MCI (Morphological Complexity Index)_Verbs_0, distrFeatures_Nouns Abstractness Distribution_Abstract_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 157 columns]\n",
      "Empty DataFrame\n",
      "Columns: [essay, predicted, probability_B1, probability_B2, probability_C1, probability_C2, scalarFeatures_Depth of the Parse Trees_0, scalarFeatures_Lexical Diversity_0, scalarFeatures_Maximal Non-Verbal Phrase - Mean_0, scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0, scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0, scalarFeatures_Non-Verbal Chains Length - Mean_0, scalarFeatures_Non-Verbal Chains Length - Std.Dev._0, scalarFeatures_Referential Cohesion - Mean_0, scalarFeatures_Referential Cohesion - Std.Dev._0, scalarFeatures_Sentence Length (in Tokens) - Mean_0, scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0, scalarFeatures_Subordinate Ratio - Mean_0, scalarFeatures_Subordinate Ratio - Std.Dev._0, scalarFeatures_Text Length (in Lemmas)_0, scalarFeatures_Text Length (in Sentences)_0, scalarFeatures_Token Length - Mean_0, scalarFeatures_Token Length - Std.Dev._0, scalarFeatures_Verbal Roots_0, simpleScalarFeatures_Lunghezza del testo_0, simpleScalarFeatures_Lunghezza media delle frasi_0, simpleScalarFeatures_Varietà lessicale_0, distrFeatures_Arity of Verbal Predicates_ 0 _0, distrFeatures_Arity of Verbal Predicates_ 1 _0, distrFeatures_Arity of Verbal Predicates_ 2 _0, distrFeatures_Arity of Verbal Predicates_ 3 _0, distrFeatures_Arity of Verbal Predicates_ 4 _0, distrFeatures_Arity of Verbal Predicates_Std.Dev._0, distrFeatures_Arity of Verbal Predicates_≥ 5_0, distrFeatures_Basic Vucabulary Rate_Fundamentals_0, distrFeatures_Basic Vucabulary Rate_High Availability_0, distrFeatures_Basic Vucabulary Rate_High Usage_0, distrFeatures_Deep Causal Cohesion_Entropy_0, distrFeatures_Deep Causal Cohesion_additive_0, distrFeatures_Deep Causal Cohesion_adversative_0, distrFeatures_Deep Causal Cohesion_alternative_0, distrFeatures_Deep Causal Cohesion_causal_0, distrFeatures_Deep Causal Cohesion_marking results_0, distrFeatures_Deep Causal Cohesion_reformulation_0, distrFeatures_Deep Causal Cohesion_temporal_0, distrFeatures_Deep Causal Cohesion_transitions_0, distrFeatures_Dependency Links Length_Max_0, distrFeatures_Dependency Links Length_Mean_0, distrFeatures_Dependency Links Length_Std.Dev._0, distrFeatures_Dependency Tags Distribution_Entropy_0, distrFeatures_Dependency Tags Distribution_acl_0, distrFeatures_Dependency Tags Distribution_advcl_0, distrFeatures_Dependency Tags Distribution_advmod_0, distrFeatures_Dependency Tags Distribution_amod_0, distrFeatures_Dependency Tags Distribution_appos_0, distrFeatures_Dependency Tags Distribution_aux_0, distrFeatures_Dependency Tags Distribution_case_0, distrFeatures_Dependency Tags Distribution_cc_0, distrFeatures_Dependency Tags Distribution_ccomp_0, distrFeatures_Dependency Tags Distribution_compound_0, distrFeatures_Dependency Tags Distribution_conj_0, distrFeatures_Dependency Tags Distribution_cop_0, distrFeatures_Dependency Tags Distribution_csubj_0, distrFeatures_Dependency Tags Distribution_det_0, distrFeatures_Dependency Tags Distribution_discourse_0, distrFeatures_Dependency Tags Distribution_dislocated_0, distrFeatures_Dependency Tags Distribution_expl_0, distrFeatures_Dependency Tags Distribution_fixed_0, distrFeatures_Dependency Tags Distribution_flat_0, distrFeatures_Dependency Tags Distribution_iobj_0, distrFeatures_Dependency Tags Distribution_mark_0, distrFeatures_Dependency Tags Distribution_nmod_0, distrFeatures_Dependency Tags Distribution_nsubj_0, distrFeatures_Dependency Tags Distribution_nummod_0, distrFeatures_Dependency Tags Distribution_obj_0, distrFeatures_Dependency Tags Distribution_obl_0, distrFeatures_Dependency Tags Distribution_parataxis_0, distrFeatures_Dependency Tags Distribution_punct_0, distrFeatures_Dependency Tags Distribution_root_0, distrFeatures_Dependency Tags Distribution_vocative_0, distrFeatures_Dependency Tags Distribution_xcomp_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0, distrFeatures_Lexical Variation Feature_Adj A_0, distrFeatures_Lexical Variation Feature_Adj B_0, distrFeatures_Lexical Variation Feature_Adv A_0, distrFeatures_Lexical Variation Feature_Adv B_0, distrFeatures_Lexical Variation Feature_Noun A_0, distrFeatures_Lexical Variation Feature_Noun B_0, distrFeatures_Lexical Variation Feature_Verb A_0, distrFeatures_Lexical Variation Feature_Verb B_0, distrFeatures_MCI (Morphological Complexity Index)_Nouns_0, distrFeatures_MCI (Morphological Complexity Index)_Verbs_0, distrFeatures_Nouns Abstractness Distribution_Abstract_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 157 columns]\n",
      "#\n",
      "    essay predicted  probability_B1  probability_B2  probability_C1   \n",
      "0    1942         1        0.491592        0.337710        0.170699  \\\n",
      "1    2068         1        0.505530        0.334998        0.159472   \n",
      "2    2118         1        0.507581        0.337750        0.154669   \n",
      "3    2339         1        0.494062        0.346853        0.159085   \n",
      "4    2584         1        0.505838        0.335086        0.159076   \n",
      "..    ...       ...             ...             ...             ...   \n",
      "273  5394         2        0.342136        0.493719        0.164145   \n",
      "274  5397         2        0.310144        0.500261        0.189595   \n",
      "275  5398         1        0.516477        0.328661        0.154863   \n",
      "276  5400         2        0.336420        0.482308        0.181272   \n",
      "277  5404         1        0.518208        0.326769        0.155023   \n",
      "\n",
      "     probability_C2  scalarFeatures_Depth of the Parse Trees_0   \n",
      "0               0.0                                        8.0  \\\n",
      "1               0.0                                        9.0   \n",
      "2               0.0                                       16.0   \n",
      "3               0.0                                        8.0   \n",
      "4               0.0                                        8.0   \n",
      "..              ...                                        ...   \n",
      "273             0.0                                       13.0   \n",
      "274             0.0                                       10.0   \n",
      "275             0.0                                       15.0   \n",
      "276             0.0                                       20.0   \n",
      "277             0.0                                        7.0   \n",
      "\n",
      "     scalarFeatures_Lexical Diversity_0   \n",
      "0                              0.385460  \\\n",
      "1                              0.377660   \n",
      "2                              0.390830   \n",
      "3                              0.357730   \n",
      "4                              0.412450   \n",
      "..                                  ...   \n",
      "273                            0.424830   \n",
      "274                            0.402850   \n",
      "275                            0.356680   \n",
      "276                            0.399050   \n",
      "277                            0.373494   \n",
      "\n",
      "     scalarFeatures_Maximal Non-Verbal Phrase - Mean_0   \n",
      "0                                            10.076923  \\\n",
      "1                                             8.727273   \n",
      "2                                             5.000000   \n",
      "3                                             5.812500   \n",
      "4                                             3.909091   \n",
      "..                                                 ...   \n",
      "273                                          13.909091   \n",
      "274                                           7.935484   \n",
      "275                                          24.222221   \n",
      "276                                          10.266666   \n",
      "277                                           5.666667   \n",
      "\n",
      "     scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0  ...   \n",
      "0                                             7.331002      ...  \\\n",
      "1                                             7.226215      ...   \n",
      "2                                             3.427827      ...   \n",
      "3                                             5.306835      ...   \n",
      "4                                             2.343269      ...   \n",
      "..                                                 ...      ...   \n",
      "273                                          21.465164      ...   \n",
      "274                                           8.929111      ...   \n",
      "275                                          26.938717      ...   \n",
      "276                                          10.443499      ...   \n",
      "277                                           3.785939      ...   \n",
      "\n",
      "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Astrattezza_0   \n",
      "0                                             0.063830                             \\\n",
      "1                                             0.000000                              \n",
      "2                                             0.206897                              \n",
      "3                                             0.136364                              \n",
      "4                                             0.125000                              \n",
      "..                                                 ...                              \n",
      "273                                           0.107527                              \n",
      "274                                           0.103896                              \n",
      "275                                           0.076923                              \n",
      "276                                           0.035714                              \n",
      "277                                           0.300000                              \n",
      "\n",
      "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Semiastrattezza_0   \n",
      "0                                             0.170213                                 \\\n",
      "1                                             0.275862                                  \n",
      "2                                             0.068966                                  \n",
      "3                                             0.613636                                  \n",
      "4                                             0.187500                                  \n",
      "..                                                 ...                                  \n",
      "273                                           0.247312                                  \n",
      "274                                           0.194805                                  \n",
      "275                                           0.215385                                  \n",
      "276                                           0.154762                                  \n",
      "277                                           0.300000                                  \n",
      "\n",
      "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Concretezza_0   \n",
      "0                                             0.765957                             \\\n",
      "1                                             0.724138                              \n",
      "2                                             0.724138                              \n",
      "3                                             0.250000                              \n",
      "4                                             0.687500                              \n",
      "..                                                 ...                              \n",
      "273                                           0.645161                              \n",
      "274                                           0.701299                              \n",
      "275                                           0.707692                              \n",
      "276                                           0.809524                              \n",
      "277                                           0.400000                              \n",
      "\n",
      "     simpleDistrFeatures_Sofisticatezza lessicale_parole vuote_0   \n",
      "0                                             0.013271            \\\n",
      "1                                             0.012333             \n",
      "2                                             0.014176             \n",
      "3                                             0.009337             \n",
      "4                                             0.012684             \n",
      "..                                                 ...             \n",
      "273                                           0.011362             \n",
      "274                                           0.012666             \n",
      "275                                           0.011170             \n",
      "276                                           0.013279             \n",
      "277                                           0.011546             \n",
      "\n",
      "     simpleDistrFeatures_Sofisticatezza lessicale_lemmi vuoti_0   \n",
      "0                                             0.011669           \\\n",
      "1                                             0.013519            \n",
      "2                                             0.011638            \n",
      "3                                             0.010098            \n",
      "4                                             0.021210            \n",
      "..                                                 ...            \n",
      "273                                           0.010719            \n",
      "274                                           0.010730            \n",
      "275                                           0.008970            \n",
      "276                                           0.009718            \n",
      "277                                           0.019820            \n",
      "\n",
      "     simpleDistrFeatures_Sofisticatezza lessicale_parole contenuto_0   \n",
      "0                                             0.000503                \\\n",
      "1                                             0.000793                 \n",
      "2                                             0.000681                 \n",
      "3                                             0.000958                 \n",
      "4                                             0.000276                 \n",
      "..                                                 ...                 \n",
      "273                                           0.000289                 \n",
      "274                                           0.000729                 \n",
      "275                                           0.000700                 \n",
      "276                                           0.000240                 \n",
      "277                                           0.000699                 \n",
      "\n",
      "     simpleDistrFeatures_Sofisticatezza lessicale_lemmi contenuto_0   \n",
      "0                                             0.000572               \\\n",
      "1                                             0.000757                \n",
      "2                                             0.000864                \n",
      "3                                             0.000742                \n",
      "4                                             0.000470                \n",
      "..                                                 ...                \n",
      "273                                           0.000342                \n",
      "274                                           0.000454                \n",
      "275                                           0.000719                \n",
      "276                                           0.000341                \n",
      "277                                           0.001291                \n",
      "\n",
      "     simpleDistrFeatures_Tasso di vocabolario di base_Fondamentali_0   \n",
      "0                                             0.942446                \\\n",
      "1                                             0.955556                 \n",
      "2                                             0.897727                 \n",
      "3                                             0.925234                 \n",
      "4                                             0.948276                 \n",
      "..                                                 ...                 \n",
      "273                                           0.867021                 \n",
      "274                                           0.875000                 \n",
      "275                                           0.954198                 \n",
      "276                                           0.849398                 \n",
      "277                                           0.906977                 \n",
      "\n",
      "     simpleDistrFeatures_Tasso di vocabolario di base_Alto uso_0   \n",
      "0                                             0.057554            \\\n",
      "1                                             0.033333             \n",
      "2                                             0.079545             \n",
      "3                                             0.065421             \n",
      "4                                             0.017241             \n",
      "..                                                 ...             \n",
      "273                                           0.095745             \n",
      "274                                           0.108696             \n",
      "275                                           0.030534             \n",
      "276                                           0.108434             \n",
      "277                                           0.069767             \n",
      "\n",
      "     simpleDistrFeatures_Tasso di vocabolario di base_Alto disponibilità_0  \n",
      "0                                             0.000000                      \n",
      "1                                             0.011111                      \n",
      "2                                             0.022727                      \n",
      "3                                             0.009346                      \n",
      "4                                             0.034483                      \n",
      "..                                                 ...                      \n",
      "273                                           0.037234                      \n",
      "274                                           0.016304                      \n",
      "275                                           0.015267                      \n",
      "276                                           0.042169                      \n",
      "277                                           0.023256                      \n",
      "\n",
      "[278 rows x 157 columns]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dtypes = defaultdict(np.float32, fn='str', predicted='category')\n",
    "\n",
    "testing_cita_malt = data_prefix + '/interim/LangLearn_Test_Data/CItA/malt.csv'\n",
    "\n",
    "df_malt_test = pd.read_csv(testing_cita_malt, sep=',', dtype=dtypes, keep_default_na=False)\n",
    "df_malt_test['predicted'].replace(['B1', 'B2', 'C1', 'C2'], [1,2,3,4], inplace=True)\n",
    "df_malt_test['predicted'] = df_malt_test['predicted'].astype(pd.CategoricalDtype(ordered=True))\n",
    "df_malt_test.rename(columns={\"fn\":\"essay\"}, inplace=True)\n",
    "df_malt_test['essay'] = df_malt_test['essay'].str.replace('.txt','')\n",
    "df_malt_test.sort_values('essay', inplace=True, ignore_index=True)\n",
    "\n",
    "df_malt_test_numbers = df_malt_test.select_dtypes('number').copy()\n",
    "df_malt_test.drop(columns=df_malt_test_numbers.columns, inplace=True)\n",
    "df_malt_test = pd.concat([df_malt_test, df_malt_vt.transform(df_malt_test_numbers)], axis=1)\n",
    "\n",
    "print(df_malt_test[df_malt_test.isna().any(axis=1)])\n",
    "print(df_malt_test[df_malt_test.isnull().any(axis=1)])\n",
    "print(\"#\")\n",
    "print(df_malt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ctap_test['essay']\n",
    "# Name: essay, Length: 468, dtype: objec\n",
    "#df_malt_test['essay']\n",
    "# Name: essay, Length: 471, dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "#nlp = spacy.load(\"it_core_news_lg\")\n",
    "\n",
    "import langlearn.dataprep.utils\n",
    "training_cita_essays_fn = data_prefix + '/interim/LangLearn_Test_Data/CItA/Essays_Test_CItA.xml'\n",
    "\n",
    "txts_test = langlearn.dataprep.utils.get_txts(testing_cita_essays_fn, shrink_whitespaces=True)\n",
    "docs.update(dict(zip(list(txts_test.keys()), list(nlp.pipe(list(txts_test.values()))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Un momento di sconforto\n",
       "Un pomeriggio caldo, come gli altri, Luigino stava nella sua cameretta a vedere la TV con il suo cane Willy. Decide di andare in cucina a prendere una bottiglietta d’acqua e la poggiò sul tavolo, e l’acqua si muoveva, si muoveva tutto!Era un terremoto, Willy spaventato va da Luigino cercarono di uscire ma c’era qualcosa che bloccava la porta, la madre era riuscita a scappare ma non trovava Luigino. Lui, ormai stanco di provare ad aprire la porta, si nascose sotto al tavolo con il suo cane. Luigino perse i sensi e sviene . Quando si risveglia era coperto di polvere e macerie ma non riusciva a capire cosa era successo, ma poi, dopo tante domande che si stava facendo si ricordò dell’accaduto. Era molto preoccupato sia per lui che per il suo cagnolino, non sapeva cosa fare, cercava di togliere un po di cose su di lui ma niente. Sentiva il rumore delle scavatrici e della gente che urlava, ma lui era troppo stanco e senza accorgersene si addormentò. Ormai erano due giorni che stava li sotto, riusciva a sopportare la sete e la fame, ma si sentiva solo, infatti, parlava sempre con il suo cane e il rumore delle scavatrici ormai gli ricordavano le grida dei bambini che giocavano e si divertivano. Ad un certo punto vede la luce che entrava da un buco, così ci fece passare Willy e gli mise un bigliettino al collo che diceva di salvarlo al più presto. Era passato un altro giorno e Luigino pensava a Willy e se qualcuno aveva letto il suo biglietto. Luigino si stava per addormentare quando sentì qualcuno gridare il suo nome, lui pensava che stava sognando e che sarebbe rimasto li per sempre o almeno finche non sistemavano la casa, ma si sbagliava, lo stavano chiamando veramente, erano sua madre, i soccorsi e anche Willy, Luigino era contento che finalmente sarebbe uscito di li , vedeva la luce del sole ed ecco che ormai era fuori. Lo portarono in ospedale e lo pulirono. Appena si svegliò festeggiarono lui, sua madre e il suo eroe Willy."
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs['1942']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author, essay, sequence_abs, predicted, probability_B1, probability_B2, probability_C1, probability_C2, scalarFeatures_Depth of the Parse Trees_0, scalarFeatures_Lexical Diversity_0, scalarFeatures_Maximal Non-Verbal Phrase - Mean_0, scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0, scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0, scalarFeatures_Non-Verbal Chains Length - Mean_0, scalarFeatures_Non-Verbal Chains Length - Std.Dev._0, scalarFeatures_Referential Cohesion - Mean_0, scalarFeatures_Referential Cohesion - Std.Dev._0, scalarFeatures_Sentence Length (in Tokens) - Mean_0, scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0, scalarFeatures_Subordinate Ratio - Mean_0, scalarFeatures_Subordinate Ratio - Std.Dev._0, scalarFeatures_Text Length (in Lemmas)_0, scalarFeatures_Text Length (in Sentences)_0, scalarFeatures_Token Length - Mean_0, scalarFeatures_Token Length - Std.Dev._0, scalarFeatures_Verbal Roots_0, simpleScalarFeatures_Lunghezza del testo_0, simpleScalarFeatures_Lunghezza media delle frasi_0, simpleScalarFeatures_Varietà lessicale_0, distrFeatures_Arity of Verbal Predicates_ 0 _0, distrFeatures_Arity of Verbal Predicates_ 1 _0, distrFeatures_Arity of Verbal Predicates_ 2 _0, distrFeatures_Arity of Verbal Predicates_ 3 _0, distrFeatures_Arity of Verbal Predicates_ 4 _0, distrFeatures_Arity of Verbal Predicates_Std.Dev._0, distrFeatures_Arity of Verbal Predicates_≥ 5_0, distrFeatures_Basic Vucabulary Rate_Fundamentals_0, distrFeatures_Basic Vucabulary Rate_High Availability_0, distrFeatures_Basic Vucabulary Rate_High Usage_0, distrFeatures_Deep Causal Cohesion_Entropy_0, distrFeatures_Deep Causal Cohesion_additive_0, distrFeatures_Deep Causal Cohesion_adversative_0, distrFeatures_Deep Causal Cohesion_alternative_0, distrFeatures_Deep Causal Cohesion_causal_0, distrFeatures_Deep Causal Cohesion_marking results_0, distrFeatures_Deep Causal Cohesion_reformulation_0, distrFeatures_Deep Causal Cohesion_temporal_0, distrFeatures_Deep Causal Cohesion_transitions_0, distrFeatures_Dependency Links Length_Max_0, distrFeatures_Dependency Links Length_Mean_0, distrFeatures_Dependency Links Length_Std.Dev._0, distrFeatures_Dependency Tags Distribution_Entropy_0, distrFeatures_Dependency Tags Distribution_acl_0, distrFeatures_Dependency Tags Distribution_advcl_0, distrFeatures_Dependency Tags Distribution_advmod_0, distrFeatures_Dependency Tags Distribution_amod_0, distrFeatures_Dependency Tags Distribution_appos_0, distrFeatures_Dependency Tags Distribution_aux_0, distrFeatures_Dependency Tags Distribution_case_0, distrFeatures_Dependency Tags Distribution_cc_0, distrFeatures_Dependency Tags Distribution_ccomp_0, distrFeatures_Dependency Tags Distribution_compound_0, distrFeatures_Dependency Tags Distribution_conj_0, distrFeatures_Dependency Tags Distribution_cop_0, distrFeatures_Dependency Tags Distribution_csubj_0, distrFeatures_Dependency Tags Distribution_det_0, distrFeatures_Dependency Tags Distribution_discourse_0, distrFeatures_Dependency Tags Distribution_dislocated_0, distrFeatures_Dependency Tags Distribution_expl_0, distrFeatures_Dependency Tags Distribution_fixed_0, distrFeatures_Dependency Tags Distribution_flat_0, distrFeatures_Dependency Tags Distribution_iobj_0, distrFeatures_Dependency Tags Distribution_mark_0, distrFeatures_Dependency Tags Distribution_nmod_0, distrFeatures_Dependency Tags Distribution_nsubj_0, distrFeatures_Dependency Tags Distribution_nummod_0, distrFeatures_Dependency Tags Distribution_obj_0, distrFeatures_Dependency Tags Distribution_obl_0, distrFeatures_Dependency Tags Distribution_parataxis_0, distrFeatures_Dependency Tags Distribution_punct_0, distrFeatures_Dependency Tags Distribution_root_0, distrFeatures_Dependency Tags Distribution_vocative_0, distrFeatures_Dependency Tags Distribution_xcomp_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0, distrFeatures_Lexical Variation Feature_Adj A_0, distrFeatures_Lexical Variation Feature_Adj B_0, distrFeatures_Lexical Variation Feature_Adv A_0, distrFeatures_Lexical Variation Feature_Adv B_0, distrFeatures_Lexical Variation Feature_Noun A_0, distrFeatures_Lexical Variation Feature_Noun B_0, distrFeatures_Lexical Variation Feature_Verb A_0, distrFeatures_Lexical Variation Feature_Verb B_0, distrFeatures_MCI (Morphological Complexity Index)_Nouns_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 159 columns]\n",
      "Empty DataFrame\n",
      "Columns: [author, essay, sequence_abs, predicted, probability_B1, probability_B2, probability_C1, probability_C2, scalarFeatures_Depth of the Parse Trees_0, scalarFeatures_Lexical Diversity_0, scalarFeatures_Maximal Non-Verbal Phrase - Mean_0, scalarFeatures_Maximal Non-Verbal Phrase - Std.Dev._0, scalarFeatures_Mean Length of Clauses (Tokens) - Mean_0, scalarFeatures_Non-Verbal Chains Length - Mean_0, scalarFeatures_Non-Verbal Chains Length - Std.Dev._0, scalarFeatures_Referential Cohesion - Mean_0, scalarFeatures_Referential Cohesion - Std.Dev._0, scalarFeatures_Sentence Length (in Tokens) - Mean_0, scalarFeatures_Sentence Length (in Tokens) - Std.Dev._0, scalarFeatures_Subordinate Ratio - Mean_0, scalarFeatures_Subordinate Ratio - Std.Dev._0, scalarFeatures_Text Length (in Lemmas)_0, scalarFeatures_Text Length (in Sentences)_0, scalarFeatures_Token Length - Mean_0, scalarFeatures_Token Length - Std.Dev._0, scalarFeatures_Verbal Roots_0, simpleScalarFeatures_Lunghezza del testo_0, simpleScalarFeatures_Lunghezza media delle frasi_0, simpleScalarFeatures_Varietà lessicale_0, distrFeatures_Arity of Verbal Predicates_ 0 _0, distrFeatures_Arity of Verbal Predicates_ 1 _0, distrFeatures_Arity of Verbal Predicates_ 2 _0, distrFeatures_Arity of Verbal Predicates_ 3 _0, distrFeatures_Arity of Verbal Predicates_ 4 _0, distrFeatures_Arity of Verbal Predicates_Std.Dev._0, distrFeatures_Arity of Verbal Predicates_≥ 5_0, distrFeatures_Basic Vucabulary Rate_Fundamentals_0, distrFeatures_Basic Vucabulary Rate_High Availability_0, distrFeatures_Basic Vucabulary Rate_High Usage_0, distrFeatures_Deep Causal Cohesion_Entropy_0, distrFeatures_Deep Causal Cohesion_additive_0, distrFeatures_Deep Causal Cohesion_adversative_0, distrFeatures_Deep Causal Cohesion_alternative_0, distrFeatures_Deep Causal Cohesion_causal_0, distrFeatures_Deep Causal Cohesion_marking results_0, distrFeatures_Deep Causal Cohesion_reformulation_0, distrFeatures_Deep Causal Cohesion_temporal_0, distrFeatures_Deep Causal Cohesion_transitions_0, distrFeatures_Dependency Links Length_Max_0, distrFeatures_Dependency Links Length_Mean_0, distrFeatures_Dependency Links Length_Std.Dev._0, distrFeatures_Dependency Tags Distribution_Entropy_0, distrFeatures_Dependency Tags Distribution_acl_0, distrFeatures_Dependency Tags Distribution_advcl_0, distrFeatures_Dependency Tags Distribution_advmod_0, distrFeatures_Dependency Tags Distribution_amod_0, distrFeatures_Dependency Tags Distribution_appos_0, distrFeatures_Dependency Tags Distribution_aux_0, distrFeatures_Dependency Tags Distribution_case_0, distrFeatures_Dependency Tags Distribution_cc_0, distrFeatures_Dependency Tags Distribution_ccomp_0, distrFeatures_Dependency Tags Distribution_compound_0, distrFeatures_Dependency Tags Distribution_conj_0, distrFeatures_Dependency Tags Distribution_cop_0, distrFeatures_Dependency Tags Distribution_csubj_0, distrFeatures_Dependency Tags Distribution_det_0, distrFeatures_Dependency Tags Distribution_discourse_0, distrFeatures_Dependency Tags Distribution_dislocated_0, distrFeatures_Dependency Tags Distribution_expl_0, distrFeatures_Dependency Tags Distribution_fixed_0, distrFeatures_Dependency Tags Distribution_flat_0, distrFeatures_Dependency Tags Distribution_iobj_0, distrFeatures_Dependency Tags Distribution_mark_0, distrFeatures_Dependency Tags Distribution_nmod_0, distrFeatures_Dependency Tags Distribution_nsubj_0, distrFeatures_Dependency Tags Distribution_nummod_0, distrFeatures_Dependency Tags Distribution_obj_0, distrFeatures_Dependency Tags Distribution_obl_0, distrFeatures_Dependency Tags Distribution_parataxis_0, distrFeatures_Dependency Tags Distribution_punct_0, distrFeatures_Dependency Tags Distribution_root_0, distrFeatures_Dependency Tags Distribution_vocative_0, distrFeatures_Dependency Tags Distribution_xcomp_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Function Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Function Token - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Lemma - Std.Dev._0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Mean_0, distrFeatures_Lexical Sophistication Feature_Lexical Token - Std.Dev._0, distrFeatures_Lexical Variation Feature_Adj A_0, distrFeatures_Lexical Variation Feature_Adj B_0, distrFeatures_Lexical Variation Feature_Adv A_0, distrFeatures_Lexical Variation Feature_Adv B_0, distrFeatures_Lexical Variation Feature_Noun A_0, distrFeatures_Lexical Variation Feature_Noun B_0, distrFeatures_Lexical Variation Feature_Verb A_0, distrFeatures_Lexical Variation Feature_Verb B_0, distrFeatures_MCI (Morphological Complexity Index)_Nouns_0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 159 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>essay</th>\n",
       "      <th>predicted</th>\n",
       "      <th>probability_B1</th>\n",
       "      <th>probability_B2</th>\n",
       "      <th>probability_C1</th>\n",
       "      <th>probability_C2</th>\n",
       "      <th>scalarFeatures_Depth of the Parse Trees_0</th>\n",
       "      <th>scalarFeatures_Lexical Diversity_0</th>\n",
       "      <th>scalarFeatures_Maximal Non-Verbal Phrase - Mean_0</th>\n",
       "      <th>...</th>\n",
       "      <th>simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Astrattezza_0</th>\n",
       "      <th>simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Semiastrattezza_0</th>\n",
       "      <th>simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Concretezza_0</th>\n",
       "      <th>simpleDistrFeatures_Sofisticatezza lessicale_parole vuote_0</th>\n",
       "      <th>simpleDistrFeatures_Sofisticatezza lessicale_lemmi vuoti_0</th>\n",
       "      <th>simpleDistrFeatures_Sofisticatezza lessicale_parole contenuto_0</th>\n",
       "      <th>simpleDistrFeatures_Sofisticatezza lessicale_lemmi contenuto_0</th>\n",
       "      <th>simpleDistrFeatures_Tasso di vocabolario di base_Fondamentali_0</th>\n",
       "      <th>simpleDistrFeatures_Tasso di vocabolario di base_Alto uso_0</th>\n",
       "      <th>simpleDistrFeatures_Tasso di vocabolario di base_Alto disponibilità_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>5388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519096</td>\n",
       "      <td>0.328663</td>\n",
       "      <td>0.152240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.38085</td>\n",
       "      <td>2.913043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>5388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519096</td>\n",
       "      <td>0.328663</td>\n",
       "      <td>0.152240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.38085</td>\n",
       "      <td>2.913043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>5388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519096</td>\n",
       "      <td>0.328663</td>\n",
       "      <td>0.152240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.38085</td>\n",
       "      <td>2.913043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>5388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519096</td>\n",
       "      <td>0.328663</td>\n",
       "      <td>0.152240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.38085</td>\n",
       "      <td>2.913043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_3116</td>\n",
       "      <td>5388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519096</td>\n",
       "      <td>0.328663</td>\n",
       "      <td>0.152240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.38085</td>\n",
       "      <td>2.913043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>A_4019</td>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515587</td>\n",
       "      <td>0.328727</td>\n",
       "      <td>0.155686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.33522</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>A_4152</td>\n",
       "      <td>5201</td>\n",
       "      <td>2</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.515729</td>\n",
       "      <td>0.161972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.37270</td>\n",
       "      <td>9.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.389830</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>0.009603</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.070513</td>\n",
       "      <td>0.006410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>A_4152</td>\n",
       "      <td>4152</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490328</td>\n",
       "      <td>0.350545</td>\n",
       "      <td>0.159126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.39547</td>\n",
       "      <td>6.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.853147</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>A_3291</td>\n",
       "      <td>3291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497829</td>\n",
       "      <td>0.351079</td>\n",
       "      <td>0.151092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.38645</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.013874</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.024793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>A_3291</td>\n",
       "      <td>5130</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513389</td>\n",
       "      <td>0.332740</td>\n",
       "      <td>0.153871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.37408</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.016320</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.835443</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.037975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     author essay predicted  probability_B1  probability_B2  probability_C1   \n",
       "0    A_3116  5388         1        0.519096        0.328663        0.152240  \\\n",
       "1    A_3116  5388         1        0.519096        0.328663        0.152240   \n",
       "2    A_3116  5388         1        0.519096        0.328663        0.152240   \n",
       "3    A_3116  5388         1        0.519096        0.328663        0.152240   \n",
       "4    A_3116  5388         1        0.519096        0.328663        0.152240   \n",
       "..      ...   ...       ...             ...             ...             ...   \n",
       "455  A_4019  4019         1        0.515587        0.328727        0.155686   \n",
       "456  A_4152  5201         2        0.322300        0.515729        0.161972   \n",
       "457  A_4152  4152         1        0.490328        0.350545        0.159126   \n",
       "458  A_3291  3291         1        0.497829        0.351079        0.151092   \n",
       "459  A_3291  5130         1        0.513389        0.332740        0.153871   \n",
       "\n",
       "     probability_C2  scalarFeatures_Depth of the Parse Trees_0   \n",
       "0               0.0                                        7.0  \\\n",
       "1               0.0                                        7.0   \n",
       "2               0.0                                        7.0   \n",
       "3               0.0                                        7.0   \n",
       "4               0.0                                        7.0   \n",
       "..              ...                                        ...   \n",
       "455             0.0                                        8.0   \n",
       "456             0.0                                       10.0   \n",
       "457             0.0                                        7.0   \n",
       "458             0.0                                       12.0   \n",
       "459             0.0                                        6.0   \n",
       "\n",
       "     scalarFeatures_Lexical Diversity_0   \n",
       "0                               0.38085  \\\n",
       "1                               0.38085   \n",
       "2                               0.38085   \n",
       "3                               0.38085   \n",
       "4                               0.38085   \n",
       "..                                  ...   \n",
       "455                             0.33522   \n",
       "456                             0.37270   \n",
       "457                             0.39547   \n",
       "458                             0.38645   \n",
       "459                             0.37408   \n",
       "\n",
       "     scalarFeatures_Maximal Non-Verbal Phrase - Mean_0  ...   \n",
       "0                                             2.913043  ...  \\\n",
       "1                                             2.913043  ...   \n",
       "2                                             2.913043  ...   \n",
       "3                                             2.913043  ...   \n",
       "4                                             2.913043  ...   \n",
       "..                                                 ...  ...   \n",
       "455                                           6.571429  ...   \n",
       "456                                           9.652174  ...   \n",
       "457                                           6.160000  ...   \n",
       "458                                           6.000000  ...   \n",
       "459                                           9.400000  ...   \n",
       "\n",
       "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Astrattezza_0   \n",
       "0                                             0.041667                             \\\n",
       "1                                             0.041667                              \n",
       "2                                             0.041667                              \n",
       "3                                             0.041667                              \n",
       "4                                             0.041667                              \n",
       "..                                                 ...                              \n",
       "455                                           0.545455                              \n",
       "456                                           0.203390                              \n",
       "457                                           0.117647                              \n",
       "458                                           0.050000                              \n",
       "459                                           0.000000                              \n",
       "\n",
       "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Semiastrattezza_0   \n",
       "0                                             0.166667                                 \\\n",
       "1                                             0.166667                                  \n",
       "2                                             0.166667                                  \n",
       "3                                             0.166667                                  \n",
       "4                                             0.166667                                  \n",
       "..                                                 ...                                  \n",
       "455                                           0.181818                                  \n",
       "456                                           0.389830                                  \n",
       "457                                           0.235294                                  \n",
       "458                                           0.133333                                  \n",
       "459                                           0.250000                                  \n",
       "\n",
       "     simpleDistrFeatures_Distribuzione dell'astrattezza/concretezza_Concretezza_0   \n",
       "0                                             0.791667                             \\\n",
       "1                                             0.791667                              \n",
       "2                                             0.791667                              \n",
       "3                                             0.791667                              \n",
       "4                                             0.791667                              \n",
       "..                                                 ...                              \n",
       "455                                           0.272727                              \n",
       "456                                           0.406780                              \n",
       "457                                           0.647059                              \n",
       "458                                           0.816667                              \n",
       "459                                           0.750000                              \n",
       "\n",
       "     simpleDistrFeatures_Sofisticatezza lessicale_parole vuote_0   \n",
       "0                                             0.010394            \\\n",
       "1                                             0.010394             \n",
       "2                                             0.010394             \n",
       "3                                             0.010394             \n",
       "4                                             0.010394             \n",
       "..                                                 ...             \n",
       "455                                           0.009242             \n",
       "456                                           0.010733             \n",
       "457                                           0.014757             \n",
       "458                                           0.013874             \n",
       "459                                           0.016320             \n",
       "\n",
       "     simpleDistrFeatures_Sofisticatezza lessicale_lemmi vuoti_0   \n",
       "0                                             0.014253           \\\n",
       "1                                             0.014253            \n",
       "2                                             0.014253            \n",
       "3                                             0.014253            \n",
       "4                                             0.014253            \n",
       "..                                                 ...            \n",
       "455                                           0.012187            \n",
       "456                                           0.009603            \n",
       "457                                           0.010823            \n",
       "458                                           0.010843            \n",
       "459                                           0.016786            \n",
       "\n",
       "     simpleDistrFeatures_Sofisticatezza lessicale_parole contenuto_0   \n",
       "0                                             0.000835                \\\n",
       "1                                             0.000835                 \n",
       "2                                             0.000835                 \n",
       "3                                             0.000835                 \n",
       "4                                             0.000835                 \n",
       "..                                                 ...                 \n",
       "455                                           0.000797                 \n",
       "456                                           0.000755                 \n",
       "457                                           0.000696                 \n",
       "458                                           0.000568                 \n",
       "459                                           0.000426                 \n",
       "\n",
       "     simpleDistrFeatures_Sofisticatezza lessicale_lemmi contenuto_0   \n",
       "0                                             0.000778               \\\n",
       "1                                             0.000778                \n",
       "2                                             0.000778                \n",
       "3                                             0.000778                \n",
       "4                                             0.000778                \n",
       "..                                                 ...                \n",
       "455                                           0.000969                \n",
       "456                                           0.000615                \n",
       "457                                           0.000420                \n",
       "458                                           0.000596                \n",
       "459                                           0.000679                \n",
       "\n",
       "     simpleDistrFeatures_Tasso di vocabolario di base_Fondamentali_0   \n",
       "0                                             0.911765                \\\n",
       "1                                             0.911765                 \n",
       "2                                             0.911765                 \n",
       "3                                             0.911765                 \n",
       "4                                             0.911765                 \n",
       "..                                                 ...                 \n",
       "455                                           0.932432                 \n",
       "456                                           0.923077                 \n",
       "457                                           0.853147                 \n",
       "458                                           0.842975                 \n",
       "459                                           0.835443                 \n",
       "\n",
       "     simpleDistrFeatures_Tasso di vocabolario di base_Alto uso_0   \n",
       "0                                             0.058824            \\\n",
       "1                                             0.058824             \n",
       "2                                             0.058824             \n",
       "3                                             0.058824             \n",
       "4                                             0.058824             \n",
       "..                                                 ...             \n",
       "455                                           0.067568             \n",
       "456                                           0.070513             \n",
       "457                                           0.132867             \n",
       "458                                           0.132231             \n",
       "459                                           0.126582             \n",
       "\n",
       "     simpleDistrFeatures_Tasso di vocabolario di base_Alto disponibilità_0  \n",
       "0                                             0.029412                      \n",
       "1                                             0.029412                      \n",
       "2                                             0.029412                      \n",
       "3                                             0.029412                      \n",
       "4                                             0.029412                      \n",
       "..                                                 ...                      \n",
       "455                                           0.000000                      \n",
       "456                                           0.006410                      \n",
       "457                                           0.013986                      \n",
       "458                                           0.024793                      \n",
       "459                                           0.037975                      \n",
       "\n",
       "[460 rows x 158 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_test = pd.merge(df_test, df_malt_test, how='outer', on='essay')\n",
    "df_full_test['author'] = df_full_test[\"author\"].astype('category')\n",
    "#df_full['essay'] = df_full[\"essay\"].astype('category')\n",
    "\n",
    "X_test = df_full_test.drop(columns='sequence_abs')\n",
    "#df_full\n",
    "\n",
    "print(df_full_test[df_full_test.isna().any(axis=1)])\n",
    "print(df_full_test[df_full_test.isnull().any(axis=1)])\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (1 of 3) Processing cat, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 1) Processing encoder, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 3) Processing ord, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 2) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing scaler, total=   0.0s\n",
      "[ColumnTransformer] ........... (3 of 3) Processing num, total=   0.0s\n",
      "[FeatureUnion] .......... (step 1 of 3) Processing pipe, total=   0.0s\n",
      "[ColumnTransformer] ... (1 of 1) Processing passthrough, total=   0.0s\n",
      "[FeatureUnion]  (step 1 of 2) Processing ct_passthrough_author, total=   0.0s\n",
      "[ColumnTransformer] ... (1 of 1) Processing passthrough, total=   0.0s\n",
      "[FeatureUnion]  (step 2 of 2) Processing ct_passthrough_numbers, total=   0.0s\n",
      "[Pipeline] ................ (step 1 of 2) Processing fu, total=   0.0s\n",
      "GN.fit: (839, 156)\n",
      "GN.transform: (839, 156)\n",
      "...GN.transformed: (839, 155)\n",
      "[Pipeline] ................ (step 2 of 2) Processing gn, total=   1.0s\n",
      "[FeatureUnion] ............ (step 2 of 3) Processing gn, total=   1.0s\n",
      "[Pipeline] .......... (step 1 of 2) Processing wordform, total=   0.1s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.8s\n",
      "[FeatureUnion] ...... (step 1 of 4) Processing spacy_wf, total=   0.9s\n",
      "[Pipeline] ............... (step 1 of 2) Processing pos, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.2s\n",
      "[FeatureUnion] ..... (step 2 of 4) Processing spacy_pos, total=   0.2s\n",
      "[Pipeline] ............... (step 1 of 2) Processing dep, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.2s\n",
      "[FeatureUnion] ..... (step 3 of 4) Processing spacy_dep, total=   0.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing morph, total=   0.6s\n",
      "[Pipeline] ............. (step 2 of 2) Processing count, total=   0.5s\n",
      "[FeatureUnion] ... (step 4 of 4) Processing spacy_morph, total=   1.1s\n",
      "[ColumnTransformer] .... (1 of 1) Processing spacy_pipe, total=   2.3s\n",
      "[FeatureUnion] ......... (step 3 of 3) Processing spacy, total=  23.9s\n",
      "[Pipeline] . (step 1 of 5) Processing combined_features, total=  25.1s\n",
      "[Pipeline] .......... (step 2 of 5) Processing to_dense, total=   0.0s\n",
      "[Pipeline] ........ (step 3 of 5) Processing scaler_std, total=   0.1s\n",
      "[Pipeline] ......... (step 4 of 5) Processing redux_pca, total=   1.0s\n",
      "[Pipeline] .. (step 5 of 5) Processing estimator_svmreg, total=   0.5s\n",
      "GN.transform: (460, 156)\n",
      "...GN.transformed: (460, 155)\n"
     ]
    }
   ],
   "source": [
    "proc_pipe.fit(X_in, y_in)\n",
    "\n",
    "y_pred = proc_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.27764026,  7.27764026,  7.27764026,  7.27764026,  7.27764026,\n",
       "        7.27764026,  4.83292432,  4.83292432,  4.83292432,  4.83292432,\n",
       "        4.97705641,  4.97705641,  4.97705641,  5.10217324,  5.10217324,\n",
       "        5.10217324,  5.10217324,  1.70614891,  1.70614891,  1.70614891,\n",
       "        1.70614891,  9.4850083 ,  9.4850083 ,  9.4850083 ,  9.4850083 ,\n",
       "        9.4850083 ,  9.4850083 ,  6.37185948,  6.37185948,  6.53852229,\n",
       "        6.53852229,  6.53852229,  6.53852229,  4.42664838,  4.42664838,\n",
       "        4.42664838,  5.88168301,  5.88168301,  5.88168301,  5.18700022,\n",
       "        5.18700022,  5.18700022,  5.18700022,  5.18700022,  6.76612744,\n",
       "        6.76612744,  6.76612744,  6.76612744,  6.40583384,  6.40583384,\n",
       "        6.40583384,  6.40583384,  6.40583384,  1.14051083,  1.14051083,\n",
       "        1.14051083,  1.14051083,  4.60640003,  4.60640003,  4.60640003,\n",
       "        4.60640003,  4.60640003,  4.62775853,  4.62775853,  4.62775853,\n",
       "        3.29418105,  3.29418105,  3.29418105,  3.29418105,  7.19101175,\n",
       "        7.19101175,  7.19101175,  7.19101175,  7.19101175,  4.93059088,\n",
       "        4.93059088,  4.93059088,  4.93059088,  4.93059088,  4.93059088,\n",
       "        4.93059088,  4.00525157,  4.00525157,  4.00525157,  4.00525157,\n",
       "        4.00525157,  5.3851354 ,  5.3851354 ,  5.3851354 ,  5.3851354 ,\n",
       "        5.3851354 ,  5.3851354 ,  5.3851354 ,  4.94954711,  4.94954711,\n",
       "        4.94954711,  4.94954711,  4.94954711,  6.27794293,  6.27794293,\n",
       "        6.27794293,  6.27794293,  6.27794293,  6.27794293,  6.46869171,\n",
       "        6.46869171,  6.46869171,  6.46869171,  3.76383318,  3.76383318,\n",
       "        3.76383318,  3.76383318,  3.76383318,  7.12327849,  7.12327849,\n",
       "        7.12327849,  7.12327849,  7.12327849,  3.15199814,  3.15199814,\n",
       "        3.15199814,  3.15199814,  3.15199814,  3.15199814,  6.07338028,\n",
       "        6.07338028,  6.07338028,  6.07338028,  6.07338028,  6.7255471 ,\n",
       "        6.7255471 ,  6.7255471 ,  6.7255471 ,  6.7255471 ,  3.07382428,\n",
       "        3.07382428,  3.07382428,  3.07382428,  6.96916314,  6.96916314,\n",
       "        6.96916314,  6.96916314,  2.5677749 ,  2.5677749 ,  2.5677749 ,\n",
       "        2.5677749 ,  3.41715047,  3.41715047,  3.41715047,  3.41715047,\n",
       "        3.59267452,  3.59267452,  3.59267452,  3.59267452,  3.59267452,\n",
       "        7.46773376,  7.46773376,  7.46773376,  5.95320544,  5.95320544,\n",
       "        5.95320544,  3.27462779,  3.27462779,  3.27462779,  3.27462779,\n",
       "        6.98055828,  6.98055828,  6.98055828,  1.73149086,  9.73248671,\n",
       "        9.79293325,  2.24892709,  4.90567762,  4.81916335,  0.52699849,\n",
       "        6.49187611, 10.1139862 ,  8.63775019,  6.8313305 ,  1.69893613,\n",
       "        6.73556767,  7.92356171,  6.8368417 ,  4.03540818,  2.6626812 ,\n",
       "        2.6626812 ,  5.47382728,  3.5118305 ,  3.54574025,  6.37130828,\n",
       "        1.94165609,  1.94165609,  5.17475141,  5.17475141,  5.17475141,\n",
       "        7.08396973,  9.78950049,  1.52439064,  7.18140159,  1.67488672,\n",
       "        6.55850838,  6.55850838,  7.06491289,  6.39824906,  3.83595576,\n",
       "        5.13716043,  4.03914333,  2.66320948,  2.66320948,  7.17387531,\n",
       "        5.81988803,  5.81988803,  4.63152135,  0.96785141,  2.21855081,\n",
       "        2.21855081,  2.21855081,  3.66487002,  4.9342623 ,  7.09356475,\n",
       "        2.68960376,  4.84667118,  4.84667118,  8.34283614,  6.15914161,\n",
       "        5.68279888,  5.68279888,  1.12731105, 10.55339893,  5.65957476,\n",
       "        3.88392005,  6.43025348,  2.48781287,  2.48781287,  4.69450164,\n",
       "        2.43079144,  6.55410546,  6.55410546,  2.62297822,  9.61554449,\n",
       "        6.44373756,  4.02183798, -0.06166312, -0.06166312,  2.15850462,\n",
       "        2.15850462,  2.15850462,  6.25848724,  5.19270632,  5.24289246,\n",
       "        4.86729516,  3.51923485,  4.50784582,  0.43216643,  0.43216643,\n",
       "        7.40621799,  4.60661601,  4.1408099 ,  5.98842514,  3.35251092,\n",
       "        1.54595498,  1.54595498,  6.56926177,  3.92531199,  6.28735058,\n",
       "        1.99552445,  1.99552445,  5.16174255,  6.91817234,  2.59866064,\n",
       "        2.59866064,  2.59866064,  4.44324843,  6.50739292,  1.68372232,\n",
       "        1.68372232,  4.92151639,  6.06043629,  6.24348539,  4.23061561,\n",
       "        4.23061561,  4.19203261,  1.8936634 ,  8.60653534,  6.56011815,\n",
       "        1.9923034 ,  1.9923034 ,  4.50254795,  5.58727768,  2.07394931,\n",
       "        2.07394931,  6.59421541,  4.36896629,  5.08601117,  2.19549696,\n",
       "        2.19549696,  6.39971395,  5.12546406,  1.40588648,  1.40588648,\n",
       "        1.40588648,  7.18393193,  4.02127437,  4.47151695,  6.02058959,\n",
       "        4.33038237,  1.20911609,  1.20911609,  1.20911609,  5.15503602,\n",
       "        5.15503602,  1.27738443,  7.33499268,  1.98314277,  6.38574783,\n",
       "        6.7693267 ,  6.7693267 ,  1.47854951,  8.20618231,  3.29939281,\n",
       "        5.06226421,  7.11584572,  5.40507971,  5.40507971,  1.59932065,\n",
       "        9.73640963,  3.89707532,  5.56438136,  6.78781388,  6.78781388,\n",
       "        2.75682855,  8.10152621,  8.5852029 ,  1.46240261,  3.55303785,\n",
       "        5.33485697,  5.11819297,  1.99967305,  4.54123357,  3.77366839,\n",
       "        5.69480869,  1.69506914,  1.69506914,  4.23144099,  6.91019262,\n",
       "        6.91019262,  6.91019262,  1.0348067 ,  9.07590579, 10.05018136,\n",
       "        8.74459167,  6.51622283,  4.60600089,  1.50597026,  5.56990593,\n",
       "        7.0766336 ,  4.73117145,  7.31394376,  2.11721476,  2.11721476,\n",
       "        4.98430557,  3.2465196 ,  3.2465196 ,  5.66165939,  6.17419584,\n",
       "        3.71732917,  2.33463804,  2.33463804,  1.76950543,  1.76950543,\n",
       "        4.11966241,  6.39776971,  4.24260941,  3.96925802,  3.76158569,\n",
       "        4.0815869 ,  6.48819865,  4.09229021,  1.53155769,  1.53155769,\n",
       "        4.57333584,  2.51059974,  2.51059974,  6.15404538,  3.08741984,\n",
       "        3.08741984,  5.75009554,  4.07730408,  3.55247772,  5.8747538 ,\n",
       "        6.69986356,  3.25698769,  3.59388062,  7.06435821,  2.88709203,\n",
       "        4.2987588 ,  6.34898739,  4.79555881,  2.06724307,  2.06724307,\n",
       "        6.63442202,  3.60730342,  6.69414632,  2.50636274,  2.50636274,\n",
       "        5.14268067,  6.57748686,  5.26012962,  2.40556738,  4.42515406,\n",
       "        3.92710757,  3.92710757,  6.06131481,  2.69408162,  4.71656439,\n",
       "        3.95627564,  5.25948293,  4.62652014,  3.03954729,  4.17476591,\n",
       "        5.65881759,  1.74384755,  5.83148265,  5.83148265,  8.66566037,\n",
       "        8.40994108,  4.29275098,  3.24315848,  3.24315848,  3.24315848,\n",
       "        6.05443855,  4.8054615 ,  6.55394359,  3.86560437,  1.21777352,\n",
       "        1.21777352,  3.50047234,  5.17655038,  5.55137148,  4.53191893,\n",
       "        2.88364428,  6.00560673,  4.71523649,  3.09896728,  3.98285691,\n",
       "        2.20505454,  7.25065557,  3.67077078,  6.19496422,  2.38042295,\n",
       "        5.86900962,  4.09768567,  4.67835214,  4.8923932 ,  2.44709569,\n",
       "        2.44709569,  7.04124556,  5.50363797,  2.77093608,  5.08774213])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5388 7.277640258631695 4853 4.977056407979215 1\n",
      "4614 5.187000215174842 5358 6.76612744401976 0\n",
      "5144 7.123278494874202 3364 4.930590878034086 1\n",
      "4749 4.4266483809151325 4814 6.5385222924788176 0\n",
      "5358 6.76612744401976 3833 5.88168300586769 1\n",
      "5162 3.763833175101253 3364 4.930590878034086 0\n",
      "5146 5.953205435951152 5400 3.2746277904089798 1\n",
      "5144 7.123278494874202 5173 6.468691710547123 1\n",
      "5380 3.4171504724099067 5400 3.2746277904089798 1\n",
      "5359 3.5926745248979244 5299 2.5677748955095625 1\n",
      "5319 6.3718594817430265 4749 4.4266483809151325 1\n",
      "4181 6.405833836620728 5358 6.76612744401976 0\n",
      "4853 4.977056407979215 5222 4.832924322358846 1\n",
      "5223 5.385135395139522 4258 4.949547111714538 1\n",
      "5192 1.7061489082798302 4853 4.977056407979215 0\n",
      "5091 6.277942926435309 5144 7.123278494874202 0\n",
      "4047 4.627758530364164 3833 5.88168300586769 0\n",
      "5400 3.2746277904089798 3794 6.9691631444001985 0\n",
      "5359 3.5926745248979244 4716 7.467733763442195 0\n",
      "5192 1.7061489082798302 3116 5.102173235944682 0\n",
      "4258 4.949547111714538 5075 4.005251573475807 1\n",
      "5292 6.073380283077942 5400 3.2746277904089798 1\n",
      "3364 4.930590878034086 5091 6.277942926435309 0\n",
      "5372 3.0738242836147185 5146 5.953205435951152 0\n",
      "4716 7.467733763442195 5400 3.2746277904089798 1\n",
      "5358 6.76612744401976 2899 4.606400030818053 1\n",
      "5146 5.953205435951152 5292 6.073380283077942 0\n",
      "3116 5.102173235944682 5319 6.3718594817430265 0\n",
      "3794 6.9691631444001985 4716 7.467733763442195 0\n",
      "4908 9.48500829905955 5222 4.832924322358846 1\n",
      "4749 4.4266483809151325 4908 9.48500829905955 0\n",
      "4908 9.48500829905955 5319 6.3718594817430265 1\n",
      "5091 6.277942926435309 5173 6.468691710547123 0\n",
      "3833 5.88168300586769 4857 1.1405108292732324 1\n",
      "4910 7.191011752621234 5162 3.763833175101253 1\n",
      "5299 2.5677748955095625 5380 3.4171504724099067 0\n",
      "5173 6.468691710547123 5223 5.385135395139522 1\n",
      "5200 6.725547103972646 5372 3.0738242836147185 1\n",
      "3364 4.930590878034086 4923 3.151998141757707 1\n",
      "5292 6.073380283077942 4716 7.467733763442195 0\n",
      "4716 7.467733763442195 5380 3.4171504724099067 1\n",
      "5200 6.725547103972646 3794 6.9691631444001985 0\n",
      "2899 4.606400030818053 4181 6.405833836620728 0\n",
      "4857 1.1405108292732324 4047 4.627758530364164 0\n",
      "5146 5.953205435951152 4716 7.467733763442195 0\n",
      "5144 7.123278494874202 5075 4.005251573475807 1\n",
      "5292 6.073380283077942 5359 3.5926745248979244 1\n",
      "5299 2.5677748955095625 4716 7.467733763442195 0\n",
      "5173 6.468691710547123 4923 3.151998141757707 1\n",
      "5173 6.468691710547123 3364 4.930590878034086 1\n",
      "5146 5.953205435951152 5299 2.5677748955095625 1\n",
      "5359 3.5926745248979244 5400 3.2746277904089798 1\n",
      "4923 3.151998141757707 5144 7.123278494874202 0\n",
      "4181 6.405833836620728 4047 4.627758530364164 1\n",
      "4749 4.4266483809151325 4853 4.977056407979215 0\n",
      "4258 4.949547111714538 5173 6.468691710547123 0\n",
      "5192 1.7061489082798302 5222 4.832924322358846 0\n",
      "5358 6.76612744401976 4857 1.1405108292732324 1\n",
      "5388 7.277640258631695 4749 4.4266483809151325 1\n",
      "5388 7.277640258631695 4814 6.5385222924788176 1\n",
      "5319 6.3718594817430265 4814 6.5385222924788176 0\n",
      "5222 4.832924322358846 4749 4.4266483809151325 1\n",
      "5223 5.385135395139522 4923 3.151998141757707 1\n",
      "4258 4.949547111714538 5162 3.763833175101253 1\n",
      "4749 4.4266483809151325 3116 5.102173235944682 0\n",
      "5372 3.0738242836147185 5380 3.4171504724099067 0\n",
      "4503 3.2941810548398758 5358 6.76612744401976 0\n",
      "3794 6.9691631444001985 5359 3.5926745248979244 1\n",
      "5144 7.123278494874202 4910 7.191011752621234 0\n",
      "2899 4.606400030818053 3833 5.88168300586769 0\n",
      "5380 3.4171504724099067 3794 6.9691631444001985 0\n",
      "4923 3.151998141757707 4258 4.949547111714538 0\n",
      "4614 5.187000215174842 4857 1.1405108292732324 1\n",
      "5359 3.5926745248979244 5200 6.725547103972646 0\n",
      "5299 2.5677748955095625 5400 3.2746277904089798 0\n",
      "4857 1.1405108292732324 4503 3.2941810548398758 0\n",
      "5388 7.277640258631695 5222 4.832924322358846 1\n",
      "5146 5.953205435951152 3794 6.9691631444001985 0\n",
      "5223 5.385135395139522 5075 4.005251573475807 1\n",
      "5200 6.725547103972646 5299 2.5677748955095625 1\n",
      "5222 4.832924322358846 5319 6.3718594817430265 0\n",
      "5222 4.832924322358846 4814 6.5385222924788176 0\n",
      "5162 3.763833175101253 5075 4.005251573475807 0\n",
      "5388 7.277640258631695 3116 5.102173235944682 1\n",
      "5359 3.5926745248979244 5380 3.4171504724099067 1\n",
      "5075 4.005251573475807 5173 6.468691710547123 0\n",
      "4908 9.48500829905955 5388 7.277640258631695 1\n",
      "5146 5.953205435951152 5359 3.5926745248979244 1\n",
      "4910 7.191011752621234 3364 4.930590878034086 1\n",
      "4258 4.949547111714538 5144 7.123278494874202 0\n",
      "5144 7.123278494874202 5162 3.763833175101253 1\n",
      "2899 4.606400030818053 4857 1.1405108292732324 1\n",
      "5388 7.277640258631695 5192 1.7061489082798302 1\n",
      "4908 9.48500829905955 5192 1.7061489082798302 1\n",
      "5292 6.073380283077942 3794 6.9691631444001985 0\n",
      "4258 4.949547111714538 4910 7.191011752621234 0\n",
      "5380 3.4171504724099067 5292 6.073380283077942 0\n",
      "5200 6.725547103972646 5292 6.073380283077942 1\n",
      "4853 4.977056407979215 5319 6.3718594817430265 0\n",
      "5173 6.468691710547123 5162 3.763833175101253 1\n",
      "4258 4.949547111714538 5091 6.277942926435309 0\n",
      "5299 2.5677748955095625 3794 6.9691631444001985 0\n",
      "4047 4.627758530364164 4614 5.187000215174842 0\n",
      "5075 4.005251573475807 4910 7.191011752621234 0\n",
      "5319 6.3718594817430265 5388 7.277640258631695 0\n",
      "4910 7.191011752621234 4923 3.151998141757707 1\n",
      "4910 7.191011752621234 5091 6.277942926435309 1\n",
      "4923 3.151998141757707 5075 4.005251573475807 0\n",
      "3794 6.9691631444001985 5372 3.0738242836147185 1\n",
      "5146 5.953205435951152 5200 6.725547103972646 0\n",
      "2899 4.606400030818053 4503 3.2941810548398758 1\n",
      "4614 5.187000215174842 2899 4.606400030818053 1\n",
      "5372 3.0738242836147185 4716 7.467733763442195 0\n",
      "4047 4.627758530364164 5358 6.76612744401976 0\n",
      "3364 4.930590878034086 5075 4.005251573475807 1\n",
      "4258 4.949547111714538 3364 4.930590878034086 1\n",
      "3116 5.102173235944682 5222 4.832924322358846 1\n",
      "5192 1.7061489082798302 4749 4.4266483809151325 0\n",
      "5223 5.385135395139522 3364 4.930590878034086 1\n",
      "4910 7.191011752621234 5223 5.385135395139522 1\n",
      "5400 3.2746277904089798 5200 6.725547103972646 0\n",
      "5192 1.7061489082798302 5319 6.3718594817430265 0\n",
      "2899 4.606400030818053 4047 4.627758530364164 0\n",
      "5200 6.725547103972646 5380 3.4171504724099067 1\n",
      "5223 5.385135395139522 5144 7.123278494874202 0\n",
      "4181 6.405833836620728 4857 1.1405108292732324 1\n",
      "5173 6.468691710547123 4910 7.191011752621234 0\n",
      "5380 3.4171504724099067 5146 5.953205435951152 0\n",
      "4923 3.151998141757707 5162 3.763833175101253 0\n",
      "4940 6.9805582766303536 5333 1.731490857462148 1\n",
      "4215 2.248927092780067 4906 4.905677623723134 0\n",
      "4983 0.5269984949112859 4922 6.4918761092577855 0\n",
      "4453 1.6989361322652436 4750 6.735567673883635 0\n",
      "3572 6.836841700938963 4077 2.662681199550879 1\n",
      "4596 5.473827275754536 3665 3.511830499431935 1\n",
      "5168 6.371308277762445 5150 1.9416560939277758 1\n",
      "4523 5.174751407961514 5195 1.5243906415375668 1\n",
      "3989 3.545740252424053 5150 1.9416560939277758 1\n",
      "3960 1.674886715640301 4445 6.558508375704619 0\n",
      "3527 3.835955761874256 4606 5.137160426864697 0\n",
      "5329 2.663209480716542 5321 7.173875309298472 0\n",
      "5187 4.63152135476432 4552 5.81988803187486 0\n",
      "5287 3.6648700210524914 4965 2.218550810456575 1\n",
      "4281 6.159141607137637 4477 4.846671176276036 1\n",
      "4375 4.035408183762973 4077 2.662681199550879 1\n",
      "5244 5.682798882400909 5090 1.1273110516290956 1\n",
      "5310 3.88392005056553 3375 2.487812871181585 1\n",
      "4509 4.694501643071899 5095 2.4307914390878897 1\n",
      "5102 6.554105464141278 4600 2.622978215606581 1\n",
      "5343 4.021837975146304 5320 -0.06166312005927045 1\n",
      "4388 6.258487242394875 4744 2.158504624412566 1\n",
      "5205 4.867295158890509 5378 4.5078458181297725 1\n",
      "5085 0.432166429804796 4323 5.988425136642117 0\n",
      "4427 3.3525109242145374 5113 1.545954981303285 1\n",
      "4922 6.4918761092577855 4945 6.831330499840493 0\n",
      "5113 1.545954981303285 4748 6.56926177147895 0\n",
      "4626 6.287350581134499 4689 1.9955244532422824 1\n",
      "5314 5.161742550946549 4465 2.5986606396440015 1\n",
      "4235 6.5073929224750575 5156 1.6837223233392653 1\n",
      "5044 4.230615607903803 5169 4.192032611579427 1\n",
      "5317 1.8936633953251851 3986 8.606535344262223 0\n",
      "5115 5.1927063181046815 4744 2.158504624412566 1\n",
      "4958 1.9923033988910295 3471 5.587277681900872 0\n",
      "3863 2.073949308971202 4300 4.368966286867651 0\n",
      "4431 2.195496955908053 5335 6.399713949073805 0\n",
      "4661 5.12546406273426 5257 1.405886479175696 1\n",
      "4965 2.218550810456575 3354 7.093564749366133 0\n",
      "5031 4.330382366767138 5247 1.2091160943311539 1\n",
      "3498 5.155036017082469 4447 1.2773844291784484 1\n",
      "5020 1.983142769974596 5326 6.385747833260866 0\n",
      "5203 6.769326697694713 5004 1.4785495106984266 1\n",
      "5249 3.2993928128584145 4921 5.062264205636324 0\n",
      "5102 6.554105464141278 5161 9.615544488238928 0\n",
      "4433 4.471516952969968 5247 1.2091160943311539 1\n",
      "5245 5.405079709136947 2339 1.5993206536538904 1\n",
      "4876 3.897075318621915 4793 5.564381356617752 0\n",
      "4922 6.4918761092577855 4907 8.637750188297384 0\n",
      "4951 6.787813883690099 5398 2.7568285451642636 1\n",
      "4648 3.5530378542157335 4622 5.334856966083753 0\n",
      "4767 6.430253484074211 3375 2.487812871181585 1\n",
      "4920 7.406217990542917 5085 0.432166429804796 1\n",
      "4666 1.9996730540738106 5128 3.7736683880898947 0\n",
      "2584 5.694808687638848 4736 1.6950691390882582 1\n",
      "4666 1.9996730540738106 4872 4.541233572447445 0\n",
      "4411 6.9101926242589125 5077 10.05018136347552 0\n",
      "4938 6.516222830340473 4694 4.60600089277149 1\n",
      "5280 1.505970255191407 5345 5.569905928512305 0\n",
      "5276 7.313943755910141 4888 2.1172147644816977 1\n",
      "3383 4.984305567892435 3678 3.246519596619821 1\n",
      "4655 3.9253119937506216 4689 1.9955244532422824 1\n",
      "4755 8.342836143380781 4477 4.846671176276036 1\n",
      "4502 3.717329165445601 4024 2.3346380412240837 1\n",
      "5340 4.119662414469958 4810 1.7695054319983439 1\n",
      "4560 4.242609411293294 5072 4.081586895368322 1\n",
      "4288 6.488198650095737 4869 1.5315576872047523 1\n",
      "5383 2.5105997430671083 4860 6.154045378443399 0\n",
      "3728 4.934262303584509 4965 2.218550810456575 1\n",
      "5234 3.087419844135781 4800 4.077304081566969 0\n",
      "4922 6.4918761092577855 4889 10.11398619603878 0\n",
      "4285 6.174195841470972 4024 2.3346380412240837 1\n",
      "4215 2.248927092780067 5166 4.819163351013302 0\n",
      "3678 3.246519596619821 4526 5.661659394315223 0\n",
      "3159 3.552477716888566 5159 6.699863557572491 0\n",
      "5076 3.256987694531603 3886 3.5938806242228387 0\n",
      "5053 2.887092027938314 4450 6.348987393944358 0\n",
      "4917 4.795558805902757 4825 2.0672430688197245 1\n",
      "4154 9.07590578879259 4411 6.9101926242589125 1\n",
      "5034 3.6073034169923606 5360 2.5063627449635195 1\n",
      "5245 5.405079709136947 4348 9.736409630347193 0\n",
      "4951 6.787813883690099 4519 8.101526210666508 0\n",
      "3813 5.142680671076762 5404 6.577486861394317 0\n",
      "5249 3.2993928128584145 5251 7.115845717241631 0\n",
      "3159 3.552477716888566 4541 5.8747538038759775 0\n",
      "5355 5.260129615542875 4852 2.4055673776534277 1\n",
      "5156 1.6837223233392653 4773 4.921516389138196 0\n",
      "4653 9.789500486291683 4523 5.174751407961514 1\n",
      "4884 4.425154064151583 4879 3.927107574397535 1\n",
      "5280 1.505970255191407 5274 7.076633599167273 0\n",
      "3498 5.155036017082469 4515 7.334992677836927 0\n",
      "3342 9.732486706767338 4940 6.9805582766303536 1\n",
      "5244 5.682798882400909 4934 10.553398925858007 0\n",
      "5235 2.6940816225866158 4564 4.716564393196881 0\n",
      "5397 6.694146324499352 5360 2.5063627449635195 1\n",
      "5085 0.432166429804796 4473 4.140809902511678 0\n",
      "5312 7.183931934338041 5257 1.405886479175696 1\n",
      "5339 3.9562756428954184 5133 5.259482932084132 0\n",
      "5384 6.918172335204975 4465 2.5986606396440015 1\n",
      "5156 1.6837223233392653 4952 6.060436291572411 0\n",
      "4552 5.81988803187486 5371 0.9678514091307376 1\n",
      "2836 4.092290205552559 4869 1.5315576872047523 1\n",
      "4560 4.242609411293294 4319 3.9692580201661087 1\n",
      "5311 3.0395472905941467 4759 4.174765910637376 0\n",
      "4317 1.7438475456518967 4514 5.831482648321402 0\n",
      "5391 4.731171453860458 4888 2.1172147644816977 1\n",
      "5065 2.6896037572174105 4477 4.846671176276036 0\n",
      "5205 4.867295158890509 5106 3.519234850892986 1\n",
      "5076 3.256987694531603 5056 7.064358214013164 0\n",
      "4825 2.0672430688197245 4987 6.634422017320311 0\n",
      "4810 1.7695054319983439 5030 6.397769708531338 0\n",
      "5306 1.4624026064762659 4648 3.5530378542157335 0\n",
      "4411 6.9101926242589125 5229 1.034806703525427 1\n",
      "4251 6.054438553658549 3926 3.243158478357629 1\n",
      "5043 3.8656043699362237 4874 1.2177735241788419 1\n",
      "3926 3.243158478357629 4715 4.805461499346619 0\n",
      "5224 3.5004723409357497 4559 5.176550382098674 0\n",
      "2068 5.551371476484779 2118 4.531918931181725 1\n",
      "5097 6.243485390972298 5044 4.230615607903803 1\n",
      "4455 8.665660368313 4514 5.831482648321402 1\n",
      "4750 6.735567673883635 1942 7.923561712163877 0\n",
      "4514 5.831482648321402 3541 8.409941075265177 0\n",
      "4697 7.0649128904912315 4445 6.558508375704619 1\n",
      "5203 6.769326697694713 4434 8.206182307815489 0\n",
      "4565 5.086011170954596 4431 2.195496955908053 1\n",
      "5101 4.292750977219204 3926 3.243158478357629 1\n",
      "4648 3.5530378542157335 4722 5.118192966642473 0\n",
      "4472 6.553943585193894 4874 1.2177735241788419 1\n",
      "4744 2.158504624412566 4608 5.242892463927994 0\n",
      "4951 6.787813883690099 4913 8.585202899720986 0\n",
      "4411 6.9101926242589125 4916 8.744591668807816 0\n",
      "4953 2.8836442770381323 3950 6.005606728708718 0\n",
      "4523 5.174751407961514 5068 7.18140158544544 0\n",
      "5275 4.715236491540032 4325 3.098967281421117 1\n",
      "5033 3.982856908232564 4962 2.205054541749043 1\n",
      "5021 7.250655567752636 5211 3.670770778164475 1\n",
      "5346 4.039143326620269 5329 2.663209480716542 1\n",
      "5262 4.502547950156567 4958 1.9923033988910295 1\n",
      "5339 3.9562756428954184 4219 4.62652014243589 0\n",
      "4576 6.443737558374315 5320 -0.06166312005927045 1\n",
      "5317 1.8936633953251851 4272 6.560118153852876 0\n",
      "5257 1.405886479175696 5387 4.021274372048602 0\n",
      "4607 6.194964216273857 3407 2.380422947096654 1\n",
      "4879 3.927107574397535 4230 6.061314807361566 0\n",
      "5353 5.869009624832593 5277 4.097685667930675 1\n",
      "4364 4.67835214042979 4019 2.447095689290181 1\n",
      "4940 6.9805582766303536 4667 9.792933252877214 0\n",
      "4736 1.6950691390882582 3877 4.231440989009157 0\n",
      "4839 4.57333583895837 5383 2.5105997430671083 1\n",
      "4677 6.594215410666536 3863 2.073949308971202 1\n",
      "5244 5.682798882400909 4745 5.659574757091549 1\n",
      "4359 5.750095537163058 5234 3.087419844135781 1\n",
      "5085 0.432166429804796 2697 4.6066160127103055 0\n",
      "5201 7.041245563745683 4152 5.503637973702581 1\n",
      "5394 4.892393199635282 4019 2.447095689290181 1\n",
      "4560 4.242609411293294 5230 3.761585694040563 1\n",
      "5311 3.0395472905941467 3740 5.658817591083135 0\n",
      "4465 2.5986606396440015 5045 4.443248427452988 0\n",
      "5149 7.083969726406111 4523 5.174751407961514 1\n",
      "5006 6.020589592669671 5247 1.2091160943311539 1\n",
      "5053 2.887092027938314 3966 4.2987588020403456 0\n",
      "4445 6.558508375704619 3925 6.3982490629412885 1\n",
      "3291 2.770936075594037 5130 5.0877421281068225 0\n",
      "5372 3.0738242836147185 5299 2.5677748955095625 1\n",
      "5372 3.0738242836147185 5400 3.2746277904089798 0\n",
      "5223 5.385135395139522 5091 6.277942926435309 0\n",
      "4814 6.5385222924788176 4853 4.977056407979215 1\n",
      "5372 3.0738242836147185 5359 3.5926745248979244 0\n",
      "3116 5.102173235944682 4814 6.5385222924788176 0\n",
      "5292 6.073380283077942 5372 3.0738242836147185 1\n",
      "5091 6.277942926435309 4923 3.151998141757707 1\n",
      "4181 6.405833836620728 4503 3.2941810548398758 1\n",
      "5075 4.005251573475807 5091 6.277942926435309 0\n",
      "3833 5.88168300586769 4503 3.2941810548398758 1\n",
      "4614 5.187000215174842 4503 3.2941810548398758 1\n",
      "5091 6.277942926435309 5162 3.763833175101253 1\n",
      "4047 4.627758530364164 4503 3.2941810548398758 1\n",
      "5192 1.7061489082798302 4814 6.5385222924788176 0\n",
      "4908 9.48500829905955 4814 6.5385222924788176 1\n"
     ]
    }
   ],
   "source": [
    "tsv_test = pd.read_csv(testing_cita_tsv, sep='\\t', dtype=str)\n",
    "tsv_test['Pred'] = -1\n",
    "for row_id, row in tsv_test.iterrows():\n",
    "    essay_1 = row['Essay_1']\n",
    "    essay_2 = row['Essay_2']\n",
    "    essay_1_pred = np.average(y_pred[X_test[X_test['essay'] == essay_1].index])\n",
    "    essay_2_pred = np.average(y_pred[X_test[X_test['essay'] == essay_2].index])\n",
    "    label = 0 if essay_1_pred <= essay_2_pred else 1\n",
    "    print(essay_1,essay_1_pred,essay_2,essay_2_pred,label)\n",
    "    tsv_test.loc[row_id, 'Pred'] = str(label)\n",
    "\n",
    "tsv_test.to_csv('cita-preds.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>essay</th>\n",
       "      <th>sequence_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_1066</td>\n",
       "      <td>1066</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A_1066</td>\n",
       "      <td>1066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A_1066</td>\n",
       "      <td>1066</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    author essay  sequence_abs\n",
       "4   A_1066  1066             6\n",
       "7   A_1066  1066             7\n",
       "10  A_1066  1066             8"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test[X_test['essay'] == '1066']\n",
    "df_test[df_test['essay'] == '1066']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evalita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
